{
  "text": " Precision predictive markets. Is this like a new term or it's like a common term? By precision, we simply mean that you predict a real world number. So instead of saying yes or no, up or down, you actually put in an exact number. Let's say 149 and my payout will be based on how close I am to the final number. Is that right? What if I am the first one in the market? Who has stakes in the pool is the one who you bet against. Can I predict 149.11, something like that? Basically... Precision predictive markets. Hi everyone and welcome to a new pod. Today we have Anam. Anam has been working in Solana for a while. We know each other for a while from the Super Team days. We'll talk through her journey of how she got into Solana, the kind of gigs she's done in the past and her current role at Trepa. She's currently working at Trepa as a blockchain engineer. Trepa is a prediction market that was launched recently on Solana. So we'll understand what goes behind the technicals of building a prediction market and her journey into becoming a blockchain engineer over the past few years. With that, Anam would love an intro from your side as well. Hi everyone, I'm Anam Ansari. I work at Trepa, which is a precision prediction market platform. And I have been involved in the Solana ecosystem for about three or four years now. And I think I got involved in the ecosystem when I was in the second year of my undergrad. When I got selected as an MLH fellow and I interned at Hubble Protocol back then, via that fellowship. And just right after the fellowship, I got the opportunity to visit Solana Hacker House. I guess it was sponsored by Foundation itself. So that's where I met the entire Super Team community and I saw the scale of opportunity the ecosystem had. And as a new student who is a beginner into tech as well as the Web3 ecosystem, it kind of stuck with me that I wanted to continue in this space. So I just started building more into the smart contract side, the backend side. And I eventually worked with 627 projects as a freelance developer as well. And I also entered and found Solana Foundation for a while as a dev rel intern. And in my last year of undergrad, I got a full-time role at Helios as a dev ex-engineer. And after working there for some time, I realized I wanted to take harder problems and bigger ownership. And that's when I decided to switch roles and go more into an engineering side, rather than dabbling both engineering and dev rel at the same time. And eventually I ended up landing a job at Trepa. And ever since, I think I joined here back in September and it has been a great time till now. Perfect. That sounds great. I think you mentioned three major milestones. One which is working with the Foundation as an intern, then working at Helios as a dev rel advocate and then now at Trepa. Do you briefly want to touch up on your journey and your day-to-day at the Foundation and at Helios? So at Foundation, I did like a three-month internship where I used to mostly work on writing modules for Solana workshop. Most of my time went into that. And after that, I took those workshops with the help of Vishal, which was also an intern at that time with me. And at Helios, my work had two pillars. One was the dev rel side of things where I would talk with our customers or users at Helios and help them resolve any issues that they had. And the second fold was basically helping them indirectly via updating the SDK, citing the documentation. So that was my day-to-day life at Helios. And right now at Trepa, I mostly handle everything related to blockchain, the integration at the backend and anything that relates to how Trepa works internally. I work on that. Correct. That sounds perfect. Let's dive into your Trepa journey now. Very interesting, you mentioned a term, precision predictive markets. Is this like a new term or is it like a common term that's, you know, I only know predictive markets, prediction markets for now. So we're trying to build a new primitive in the prediction market space. And by precision, we simply mean that you predict a real world number. So instead of saying yes or no, up or down, you actually put in an exact number or somewhat closer to what you feel the outcome would be. So it's not something like you need to actually get this exact number to win. It's like how close you are to the outcome. Your rewards are essentially calculated in that way. Correct. So if I go to Polymarket or Calsea, I can only select if so above 150 or below 150. But on Trepa, I can predict a number, let's say 149 and my payout will be based on how close I am to the final number. Is that right? Yeah. So you just need to enter like whatever number you believe or you're convicted that, OK, I want to put in this number, let's say $149 for Sol. I know it's not the case right now, but let's say, let's say you put in $149 for Sol and you also put in some stake. And at the end, what we do is we at Trepa, we have a accuracy weighted mechanism in a perimitual pool system. I'll just break it down in simpler terms. So by perimitual, what we mean is whoever who has entered into this pool and stake some money, whatever, if you win, you get from that pool itself. So you're essentially betting against everyone who is inside that pool. So that's how you get rewarded. And the amount that you get rewarded is based on three things. One is how accurate you are. So we get a normalized error after the outcome is reached. And after the accuracy, we look into how much stake you put in. So if you put in a higher stake and you were more accurate, then you get more payout. And the last thing is you also have a time edge. So if you predicted quite early, then you also have that edge. So it's a function of accuracy, your stake and time. So these three things involved in a complex calculation decides your payout. And it's a very convex payout curve. So it could somehow if you're very accurate, it feels like a jackpot because you were the closest one. Got it. That makes sense. I can already think of a few challenges in building something like this. For example, on a polymarket or a Kashi, I think I mean B2B. So you're essentially trading against someone else. You both get some sort of stocks which eventually land up to a zero or a one. So fairly predictable. One very first sort of contention that I get is what if I am the first one in the market? I put in a thousand dollars worth of stake. I predicted a price of 149. And let's say it landed at 150 and no one else ended up participating in this market. So what happens here is Trepa. So you're not betting against us. If you were the only one in the pool, obviously you'll get the money back. We won't add any we won't add any bets from our side. Or it's not like you're playing against us. It just who has stakes in the pool is the is the one who you bet against. Correct. So it might happen. I might be extremely precisely correct. But if no one else participated in the market, I'll just get back my money. Yeah. Got it. Which might lead to a bunch of chicken and egg challenges. Right. If you don't have enough fingers, then you know, there's not enough incentive for someone to play. So a little more of I guess questions around marketing. Is there anything specific around, you know, how you are trying to challenge this, tackle this specific challenge of you probably need at least 100 people participating on a market for it to be liquid? Are you doing market making yourself participating in markets yourself? Or are you getting other market makers? You know, has it been tough to convince market makers who are already on products like Kalsi and Polymarket to come over to, you know, a new primitive like this? So we don't have any market meetings currently, just you play with whoever predicts in the pool and then this 50 percent of the stake made stake weighted median gets to be the winner. So it's not just one winner who's the most accurate. What we do is we order them based on their accuracy and then we get the cumulative stake and whoever is the like anyone about the median 50 percent stake weight would be the winner and then the payout will be calculated after that. And yeah, there is no market making involved at this point right now. Got it. Makes sense. And when can I predict like 149.1111 something like that? When we create a pool on our platform, we also set the value of precision. So we set the number of decimals you can predict to because we don't want any mathematical issue at the end or the client side. It does not mean that you don't get to be accurate. It's just there so that you don't end up putting seven or six decimals at the end of your number. So it highly depends on the value that you're predicting. So let's say you're predicting population data or GDP, which can be a very big number, right? So we have steps added, which could make sure that you just predict like four billion or four point one billion or four point two billion. You don't actually enter a very big number instead. And similarly for sole price. So let's say for Solana, we I think have like two decimal places. So you can predict 140.62. And for Bitcoin, we don't have that much precision because it's a very big numbers. I think somewhere around 50 60k right now. So we have like, I guess, a step of one or ten dollars maybe. So we have two things. We have steps and we have precision as well based on the decimal that you can put in. Got it. Sense. So I heard that you've gone through a few, you know, through a few upgrades in the last few months. You launched Treppa V1 and the last three months you moved to V2. That's like a very big change to change things at the protocol level. So what do you think went wrong with version one that you had to start over and, you know, create a new version to even before, you know, any traction? So when I joined Treppa, we already had version one, which was live on DevNet and we had a lot of better testers. So version one was very good to validate the idea because before we kind of stuck into precision prediction, we like pivoted a lot and experimented a lot with different ideas like social prediction and everything. So V1 was built in stealth mode where you're shipping just to validate that if this works or not. And once we once I actually looked over the code, I realized there were a few things that could be improved. And that's why it needed. We needed to start it over instead of just iterating over the current version. If you don't mind me getting more technical inside it. So basically, first thing I noticed is the account layout structure that we have. We had an anchor program. So the structure that we have for like a PD account, it was very restrictive. You cannot put in more. It didn't have any reserved bytes so that you can't expand the account structure in future. And I know you can just create a new contract. But for let's say small feature updates, because we added a step feature, I guess, a month back, even after we launched. So that is something that we were able to incorporate without creating a new contract is we could increase the account. We could add new variables in the account structure. Right. So that's the first thing that I wanted to change. And second thing was related to scaling as it's a consumer platform where users would be clicking a lot of buttons, making a lot of transaction, let's say for predicting, updating the stake, claiming the rewards. It also means that data is getting stored on chain. So we need to be mindful of what we store. I know when we write a contract, we tend to write, put everything on chain, like let's put everything related to the user. But at some point, you may need to draw a line of what you actually end up storing on chain, what will help in your logic and what is like redundant data. Right. So these were the two things that I wanted to make sure that we think through and we take in the cost. So I actually sat down and at that time, I guess, sold was $200. So I did some calculations based on how much it will cost to store user prediction. And we also ended up adding a new instruction to close prediction accounts. So after the pool is over, after some time, we close the accounts as not needed and then claim the fees back. If we are sponsoring, we claim it for ourselves. If the user is sponsoring, they get it back automatically. So you're saying changes are made more around optimizing the existing contract and not in terms of how the contract works or the math. Have you gone through security audit and what was the process like specifically because this is a new sort of a primitive that you created? Was it hard for the auditors to be able to understand the project or other new set of attack vectors when it comes to a new primitive like this? So before our launch, we went through an audit with AdWare Labs and we got a contract as well as a utility library, which basically caused a contract audited. And it was a very amazing experience. The team is really great at AdWare Labs with prediction market. We had an onboarding call and because it's very different from what Polymarket or Kalshi is, it's basically running on math and you have a very different set of logic where money is going inside a single pool and it's coming out from that. It's not you're not creating tokens or trading with those tokens. So I feel like the auditors at AdWare Labs are really good at understanding what we're building and they did a great job with our audit itself. We didn't find any critical issue with the contract at all. I know it's a kind of like a self compliment. The only important one, which I didn't know personally and I got to know after the audit was emitting CPI. So basically on Solana, you could emit program logs. And I was actually relying on them to get the prediction a user made because to me, it didn't make sense to put it on chain. We only put stake amount on chain in a PDA and we were emitting the data, the prediction that a user was making via program logs. And we had an indexer which will scoop up everything and store it in our database so that it reflects on our UI itself. One thing I didn't realize that RPC providers, they can actually truncate your program logs. I guess somewhere around 12 KB they allow. And that could be an issue. We could end up missing some predictions that users made. Right. So the alternative to that is just using an emit CPI macro instead of an emit macro. It's a very no op stuff that you add. What it does, it calls the same instruction again with the instruction data as the log that you wanted to pass. You pass it as an instruction data. So it's there. You can always fetch the transaction and get all the data that you want directly instead of relying on the logs. So that is something which was quite eye opening that I saw that I noticed that this could be an issue. All right. Very interesting. You mentioned a very intriguing architecture right now, which is you decide what to store on chain and what not to store on chain. And there are things that are logged in the program or in an instruction that you actually scoop up through. Can you talk to maybe specifically as to a few examples of maybe not in Trepa, maybe in Trepa where this architecture sort of depends? Because mostly from what I can tell or most places I've seen, you just store everything on chain and you want to avoid the complexity and you sort of are for more companies at least you're offloading the rent to the end user. So it doesn't matter if you're storing more. I think in your case, Trepa sponsors the gas if I'm not wrong. But I'd love to know one specific use case, this architecture specifically makes sense. You said the prediction, right? You mentioned a yes, not a yes or no. Sorry. In your case, like a number that is so that prediction is never stored on chain in a structure. It is just logged in a program. Is that correct? Yeah. So, okay. There's a lot of questions here. I'll just start with what I had in my mind. So what we wanted to do that from the start, we had the idea that we would sponsor the gas fees given the predictions are made in USTC. We weren't want a user to come in and put two types of tokens like soul and USTC because it's very confusing for the user. So we decided that we'll sponsor the fees, but sponsoring fees is a very different issue where you need to make sure that the cost is optimized for yourself as well. You don't end up paying for a lot. So that's why we needed I needed to be very deliberate with how the account structure is so that we only store what matters. Now, I would have personally stored the stake amount of like a lot of chain in the instruction as well. The only reason I stored it on on chain in a PDA account is because we also have a feature of updating a stake value. So that that's why if you want to update your stake, we checked with the previous stake to increase the stake amount. Right. So that's the only reason why I've saved it. If it was not there, I would have just had an empty PDA maybe with a bump value for prediction estimate. Now, it might feel like it's a very dicey architecture where it's not saved on chain, but you can always fetch the transaction and see like if you go on soul scan right now and in the setting you paste any ideal and if that ideal has this self CPI, you can pass it easily and see the prediction value that is being put. So it's not like it's not completely on chain. It's still there in the instruction data or the transaction that you just called. And when we resolve the pools, we make sure that the indexer is not lagging. We're not missing any transactions. So we make sure of that as well. I feel like this architecture is very good for consumer applications and even deepened protocols, right? Where you say if you're like, let's say you're saving certain kind of data on chain for deep into get rewards. So at the end, I feel like have you heard I guess at Helium, they have this library called Tuk Tuk to like reclaim and I don't remember it quite well. So cost actually becomes a very big major thing once you scale and you have that many users and you're making so much you can't keep on storing so much data on chain. So even if we sponsor fees, we need to make sure that we don't end up sponsoring so much that our sponsor wallet keeps running out time to time and it doesn't affect the users. So I don't think so. There's an issue with the architecture will miss any predictions. I hope I answered your question because there are like multiple questions. If I miss something, you can just let me know. Do you answer most of it? Is this like common pattern in Solana to log things and not sort them on chain? You know, throwing nexus to them or is this something novel that you saw over here? I feel like the five protocols do that as well. I might have taken inspiration for some there because I've always looked into like the five protocols that are there on chain or if they have open source their code. But I feel like some do like emit CPI logs via the instruction data itself. I realized it later when I was looking at some of the protocols. I'm not sure if they are critical data, but they might be something which is of use for they might have some indexing services as well. All right. Makes sense. On that note, I would love to know three, you know, top contracts that you think people can learn a lot from. Three contracts which you could learn from. I think Camino is open source right now. K-Land. I've always referred to that. I mean, I used to like look at a lot. I don't think so. It's a very clean architecture wise, but you get to know a lot of things of how like a protocol such as K-Land and stuff write their code and also Squads protocol is very clean. Like their code is at very good quality that you could look at. So K-Land, Squads. Apart from that, yeah, I don't think so. I would recommend any other contracts apart from these two. Yeah. All right. I think I have one more question, which is what's next for Trepar? What are you working on right now? So we're working on something called as Flash Pools. I guess it's going to come out soon, maybe by the end of the month. It's basically price predictions where you predict in a very shorter window. I know people will like to see the price chart move up and down and predict really quick and then just get to know if they want or not instead of waiting for more time. So this is something that we're actively working on right now. All right. What is the timeline of this as in the Flash trade? Like is it I get it every 20 seconds. What would the whole price be in the next 20 seconds? Something like that. Right now, I'm not sure if it'll change it, but I feel like it's going to be like a two minute pool cycle where you predict for one minute, wait for one minute. And so you just predict for the next two minutes. Got it. Makes sense. And there's a lot of interesting things like UI wise you could do here. Have you seen the tile trading? Yeah, you can just click on a bunch of tiles and if the line moves your tile, you make money. It's quite good. Like clicking on small tiles. It's just I think from UI wise, we need to make sure that user knows what they're predicting and they're just like clicking random things. Ruben has a very whole idea about the UI stuff. Got it. Makes sense. How big is the team right now? How many engineers do you have? So the entire team is like for full time, we have six people. It's a very small team. And for technical engineering side of us, there's me, there's Ruben, then there's our CTO Leon. So we all three work together to ship things fast and I think we are doing good at this point. Got it. And in the future, if you're ever hiring, what should people expect in the interview process? What should they have their resume to be able to get an interview at Trava? If there's any role that you feel like would help Trappa, you could always DM or see you on Telegram or Twitter or maybe just DM me if I see something I could always forward. For hiring, I don't think so. We have done like an official hiring where we announced it. It's always been like I met the co-founder, John, at network school last year and I got involved as a contract with work first and then I got offered the full time role. For Ruben, I guess I referred him via someone. So it's very unofficial process. But if there's something that you could help out with us, just reach out to John on his Twitter. Got it. I'm assuming that you didn't have an interview process, but you do have an interview process. Do you generally have an interview process for new engineers? I mean, yeah, if we hire again, we'll have an interview process. For me, I got started helping them with something related to decentralizing their work flow. And then I had few calls with them back and forth. There was no particular like technical round per se. It was mostly discussion on how I think things could be implemented or what kind of architecture I can use. So I believe there was no technical DSA round or a coding round as such. Got it. But if someone joins now, they'd probably expect to go through a standard interview process. Yeah, I don't think so. There will be a DSA round, but yeah, maybe a take away home assignment or building something. Got it. Makes sense. That's all the questions I had. Thank you so much, Anam for your time. Is there anything else you'd like to add for the audience? People who are currently thinking of getting into Solana or specifically want to be maybe blockchain engineers or smart contract engineers because it's hard to find people who specifically work on smart contracts. For me, I would say like if you are someone who's getting started particularly in writing Solana smart contracts, just start with anchor. You don't have to go through the steep learning curve of learning Rust by heart or something or just follow some basic tutorials in Rust. Start with anchor. It's a very good framework and a lot of good protocols you use it because it's good for consumer applications, right? Unless until you reach that level where you need to optimize everything by computer nets, then go with Pinocchio or native Rust or something like that. But if you start optimizing at just beginner level where you're still learning Rust and you're writing like Pinocchio, you'll just end up confusing yourself. Start with anchor. Make something work. When something clicks, you get more excited and you start looking into how to optimize this now, right? So for it's a very niche user base. So I'm just saying that if you're looking into writing Solana smart contracts, start with anchor framework. Got it. Makes sense on that note. Thank you so much for your time. Hopefully it was an interesting part for the audience and we'll see you guys in the next one. Thank you. Bye bye.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 3.24,
      "text": " Precision predictive markets. Is this like a new term or it's like a common term?",
      "tokens": [
        50364,
        6001,
        40832,
        35521,
        8383,
        13,
        1119,
        341,
        411,
        257,
        777,
        1433,
        420,
        309,
        311,
        411,
        257,
        2689,
        1433,
        30,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 1,
      "seek": 0,
      "start": 3.24,
      "end": 7.72,
      "text": " By precision, we simply mean that you predict a real world number.",
      "tokens": [
        50526,
        3146,
        18356,
        11,
        321,
        2935,
        914,
        300,
        291,
        6069,
        257,
        957,
        1002,
        1230,
        13,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 2,
      "seek": 0,
      "start": 7.72,
      "end": 13.32,
      "text": " So instead of saying yes or no, up or down, you actually put in an exact number.",
      "tokens": [
        50750,
        407,
        2602,
        295,
        1566,
        2086,
        420,
        572,
        11,
        493,
        420,
        760,
        11,
        291,
        767,
        829,
        294,
        364,
        1900,
        1230,
        13,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 3,
      "seek": 0,
      "start": 13.32,
      "end": 17.32,
      "text": " Let's say 149 and my payout will be based on how close I am to the final number.",
      "tokens": [
        51030,
        961,
        311,
        584,
        3499,
        24,
        293,
        452,
        1689,
        346,
        486,
        312,
        2361,
        322,
        577,
        1998,
        286,
        669,
        281,
        264,
        2572,
        1230,
        13,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 4,
      "seek": 0,
      "start": 17.32,
      "end": 19.88,
      "text": " Is that right? What if I am the first one in the market?",
      "tokens": [
        51230,
        1119,
        300,
        558,
        30,
        708,
        498,
        286,
        669,
        264,
        700,
        472,
        294,
        264,
        2142,
        30,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 5,
      "seek": 0,
      "start": 19.88,
      "end": 23.04,
      "text": " Who has stakes in the pool is the one who you bet against.",
      "tokens": [
        51358,
        2102,
        575,
        28429,
        294,
        264,
        7005,
        307,
        264,
        472,
        567,
        291,
        778,
        1970,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 6,
      "seek": 0,
      "start": 23.04,
      "end": 26.12,
      "text": " Can I predict 149.11, something like that?",
      "tokens": [
        51516,
        1664,
        286,
        6069,
        3499,
        24,
        13,
        5348,
        11,
        746,
        411,
        300,
        30,
        51670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 7,
      "seek": 0,
      "start": 26.12,
      "end": 26.96,
      "text": " Basically...",
      "tokens": [
        51670,
        8537,
        485,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1898384659378617,
      "compression_ratio": 1.6450511945392492,
      "no_speech_prob": 0.05118732899427414
    },
    {
      "id": 8,
      "seek": 3000,
      "start": 30.0,
      "end": 32.0,
      "text": " Precision predictive markets.",
      "tokens": [
        50364,
        6001,
        40832,
        35521,
        8383,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 9,
      "seek": 3000,
      "start": 38.76,
      "end": 40.64,
      "text": " Hi everyone and welcome to a new pod.",
      "tokens": [
        50802,
        2421,
        1518,
        293,
        2928,
        281,
        257,
        777,
        2497,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 10,
      "seek": 3000,
      "start": 40.64,
      "end": 41.76,
      "text": " Today we have Anam.",
      "tokens": [
        50896,
        2692,
        321,
        362,
        1107,
        335,
        13,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 11,
      "seek": 3000,
      "start": 41.76,
      "end": 43.96,
      "text": " Anam has been working in Solana for a while.",
      "tokens": [
        50952,
        1107,
        335,
        575,
        668,
        1364,
        294,
        7026,
        2095,
        337,
        257,
        1339,
        13,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 12,
      "seek": 3000,
      "start": 43.96,
      "end": 46.64,
      "text": " We know each other for a while from the Super Team days.",
      "tokens": [
        51062,
        492,
        458,
        1184,
        661,
        337,
        257,
        1339,
        490,
        264,
        4548,
        7606,
        1708,
        13,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 13,
      "seek": 3000,
      "start": 46.64,
      "end": 49.0,
      "text": " We'll talk through her journey of how she got into Solana,",
      "tokens": [
        51196,
        492,
        603,
        751,
        807,
        720,
        4671,
        295,
        577,
        750,
        658,
        666,
        7026,
        2095,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 14,
      "seek": 3000,
      "start": 49.0,
      "end": 53.0,
      "text": " the kind of gigs she's done in the past and her current role at Trepa.",
      "tokens": [
        51314,
        264,
        733,
        295,
        34586,
        750,
        311,
        1096,
        294,
        264,
        1791,
        293,
        720,
        2190,
        3090,
        412,
        8648,
        4306,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 15,
      "seek": 3000,
      "start": 53.0,
      "end": 55.519999999999996,
      "text": " She's currently working at Trepa as a blockchain engineer.",
      "tokens": [
        51514,
        1240,
        311,
        4362,
        1364,
        412,
        8648,
        4306,
        382,
        257,
        17176,
        11403,
        13,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 16,
      "seek": 3000,
      "start": 55.519999999999996,
      "end": 58.64,
      "text": " Trepa is a prediction market that was launched recently on Solana.",
      "tokens": [
        51640,
        8648,
        4306,
        307,
        257,
        17630,
        2142,
        300,
        390,
        8730,
        3938,
        322,
        7026,
        2095,
        13,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20080329150688359,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.030388502404093742
    },
    {
      "id": 17,
      "seek": 5864,
      "start": 58.68,
      "end": 62.92,
      "text": " So we'll understand what goes behind the technicals of building a prediction market",
      "tokens": [
        50366,
        407,
        321,
        603,
        1223,
        437,
        1709,
        2261,
        264,
        6191,
        82,
        295,
        2390,
        257,
        17630,
        2142,
        50578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14620014190673827,
      "compression_ratio": 1.5686274509803921,
      "no_speech_prob": 0.0052748778834939
    },
    {
      "id": 18,
      "seek": 5864,
      "start": 62.92,
      "end": 66.08,
      "text": " and her journey into becoming a blockchain engineer over the past few years.",
      "tokens": [
        50578,
        293,
        720,
        4671,
        666,
        5617,
        257,
        17176,
        11403,
        670,
        264,
        1791,
        1326,
        924,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14620014190673827,
      "compression_ratio": 1.5686274509803921,
      "no_speech_prob": 0.0052748778834939
    },
    {
      "id": 19,
      "seek": 5864,
      "start": 66.08,
      "end": 68.8,
      "text": " With that, Anam would love an intro from your side as well.",
      "tokens": [
        50736,
        2022,
        300,
        11,
        1107,
        335,
        576,
        959,
        364,
        12897,
        490,
        428,
        1252,
        382,
        731,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14620014190673827,
      "compression_ratio": 1.5686274509803921,
      "no_speech_prob": 0.0052748778834939
    },
    {
      "id": 20,
      "seek": 5864,
      "start": 68.8,
      "end": 70.6,
      "text": " Hi everyone, I'm Anam Ansari.",
      "tokens": [
        50872,
        2421,
        1518,
        11,
        286,
        478,
        1107,
        335,
        14590,
        3504,
        13,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14620014190673827,
      "compression_ratio": 1.5686274509803921,
      "no_speech_prob": 0.0052748778834939
    },
    {
      "id": 21,
      "seek": 5864,
      "start": 70.6,
      "end": 75.96000000000001,
      "text": " I work at Trepa, which is a precision prediction market platform.",
      "tokens": [
        50962,
        286,
        589,
        412,
        8648,
        4306,
        11,
        597,
        307,
        257,
        18356,
        17630,
        2142,
        3663,
        13,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14620014190673827,
      "compression_ratio": 1.5686274509803921,
      "no_speech_prob": 0.0052748778834939
    },
    {
      "id": 22,
      "seek": 5864,
      "start": 75.96000000000001,
      "end": 82.56,
      "text": " And I have been involved in the Solana ecosystem for about three or four years now.",
      "tokens": [
        51230,
        400,
        286,
        362,
        668,
        3288,
        294,
        264,
        7026,
        2095,
        11311,
        337,
        466,
        1045,
        420,
        1451,
        924,
        586,
        13,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14620014190673827,
      "compression_ratio": 1.5686274509803921,
      "no_speech_prob": 0.0052748778834939
    },
    {
      "id": 23,
      "seek": 8256,
      "start": 82.60000000000001,
      "end": 89.8,
      "text": " And I think I got involved in the ecosystem when I was in the second year of my undergrad.",
      "tokens": [
        50366,
        400,
        286,
        519,
        286,
        658,
        3288,
        294,
        264,
        11311,
        562,
        286,
        390,
        294,
        264,
        1150,
        1064,
        295,
        452,
        14295,
        13,
        50726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22054711307387753,
      "compression_ratio": 1.5161290322580645,
      "no_speech_prob": 0.2357351928949356
    },
    {
      "id": 24,
      "seek": 8256,
      "start": 89.8,
      "end": 97.52000000000001,
      "text": " When I got selected as an MLH fellow and I interned at Hubble Protocol back then,",
      "tokens": [
        50726,
        1133,
        286,
        658,
        8209,
        382,
        364,
        21601,
        39,
        7177,
        293,
        286,
        2154,
        292,
        412,
        42317,
        48753,
        646,
        550,
        11,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22054711307387753,
      "compression_ratio": 1.5161290322580645,
      "no_speech_prob": 0.2357351928949356
    },
    {
      "id": 25,
      "seek": 8256,
      "start": 97.52000000000001,
      "end": 99.76,
      "text": " via that fellowship.",
      "tokens": [
        51112,
        5766,
        300,
        24989,
        13,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22054711307387753,
      "compression_ratio": 1.5161290322580645,
      "no_speech_prob": 0.2357351928949356
    },
    {
      "id": 26,
      "seek": 8256,
      "start": 99.76,
      "end": 106.52000000000001,
      "text": " And just right after the fellowship, I got the opportunity to visit Solana Hacker House.",
      "tokens": [
        51224,
        400,
        445,
        558,
        934,
        264,
        24989,
        11,
        286,
        658,
        264,
        2650,
        281,
        3441,
        7026,
        2095,
        389,
        23599,
        4928,
        13,
        51562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22054711307387753,
      "compression_ratio": 1.5161290322580645,
      "no_speech_prob": 0.2357351928949356
    },
    {
      "id": 27,
      "seek": 8256,
      "start": 106.52000000000001,
      "end": 110.0,
      "text": " I guess it was sponsored by Foundation itself.",
      "tokens": [
        51562,
        286,
        2041,
        309,
        390,
        16621,
        538,
        10335,
        2564,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22054711307387753,
      "compression_ratio": 1.5161290322580645,
      "no_speech_prob": 0.2357351928949356
    },
    {
      "id": 28,
      "seek": 11000,
      "start": 110.04,
      "end": 116.92,
      "text": " So that's where I met the entire Super Team community and I saw the scale of opportunity the ecosystem had.",
      "tokens": [
        50366,
        407,
        300,
        311,
        689,
        286,
        1131,
        264,
        2302,
        4548,
        7606,
        1768,
        293,
        286,
        1866,
        264,
        4373,
        295,
        2650,
        264,
        11311,
        632,
        13,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1925907905655678,
      "compression_ratio": 1.579150579150579,
      "no_speech_prob": 0.003036828711628914
    },
    {
      "id": 29,
      "seek": 11000,
      "start": 116.92,
      "end": 122.44,
      "text": " And as a new student who is a beginner into tech as well as the Web3 ecosystem,",
      "tokens": [
        50710,
        400,
        382,
        257,
        777,
        3107,
        567,
        307,
        257,
        22080,
        666,
        7553,
        382,
        731,
        382,
        264,
        9573,
        18,
        11311,
        11,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1925907905655678,
      "compression_ratio": 1.579150579150579,
      "no_speech_prob": 0.003036828711628914
    },
    {
      "id": 30,
      "seek": 11000,
      "start": 122.44,
      "end": 126.28,
      "text": " it kind of stuck with me that I wanted to continue in this space.",
      "tokens": [
        50986,
        309,
        733,
        295,
        5541,
        365,
        385,
        300,
        286,
        1415,
        281,
        2354,
        294,
        341,
        1901,
        13,
        51178
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1925907905655678,
      "compression_ratio": 1.579150579150579,
      "no_speech_prob": 0.003036828711628914
    },
    {
      "id": 31,
      "seek": 11000,
      "start": 126.28,
      "end": 131.92000000000002,
      "text": " So I just started building more into the smart contract side, the backend side.",
      "tokens": [
        51178,
        407,
        286,
        445,
        1409,
        2390,
        544,
        666,
        264,
        4069,
        4364,
        1252,
        11,
        264,
        38087,
        1252,
        13,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1925907905655678,
      "compression_ratio": 1.579150579150579,
      "no_speech_prob": 0.003036828711628914
    },
    {
      "id": 32,
      "seek": 11000,
      "start": 131.92000000000002,
      "end": 138.76,
      "text": " And I eventually worked with 627 projects as a freelance developer as well.",
      "tokens": [
        51460,
        400,
        286,
        4728,
        2732,
        365,
        1386,
        10076,
        4455,
        382,
        257,
        47875,
        10754,
        382,
        731,
        13,
        51802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1925907905655678,
      "compression_ratio": 1.579150579150579,
      "no_speech_prob": 0.003036828711628914
    },
    {
      "id": 33,
      "seek": 13876,
      "start": 138.79999999999998,
      "end": 146.44,
      "text": " And I also entered and found Solana Foundation for a while as a dev rel intern.",
      "tokens": [
        50366,
        400,
        286,
        611,
        9065,
        293,
        1352,
        7026,
        2095,
        10335,
        337,
        257,
        1339,
        382,
        257,
        1905,
        1039,
        2154,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1557005578344995,
      "compression_ratio": 1.5758928571428572,
      "no_speech_prob": 0.00044293756945990026
    },
    {
      "id": 34,
      "seek": 13876,
      "start": 146.44,
      "end": 155.79999999999998,
      "text": " And in my last year of undergrad, I got a full-time role at Helios as a dev ex-engineer.",
      "tokens": [
        50748,
        400,
        294,
        452,
        1036,
        1064,
        295,
        14295,
        11,
        286,
        658,
        257,
        1577,
        12,
        3766,
        3090,
        412,
        6128,
        2717,
        382,
        257,
        1905,
        454,
        12,
        25609,
        260,
        13,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1557005578344995,
      "compression_ratio": 1.5758928571428572,
      "no_speech_prob": 0.00044293756945990026
    },
    {
      "id": 35,
      "seek": 13876,
      "start": 155.79999999999998,
      "end": 162.76,
      "text": " And after working there for some time, I realized I wanted to take harder problems and bigger ownership.",
      "tokens": [
        51216,
        400,
        934,
        1364,
        456,
        337,
        512,
        565,
        11,
        286,
        5334,
        286,
        1415,
        281,
        747,
        6081,
        2740,
        293,
        3801,
        15279,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1557005578344995,
      "compression_ratio": 1.5758928571428572,
      "no_speech_prob": 0.00044293756945990026
    },
    {
      "id": 36,
      "seek": 13876,
      "start": 162.76,
      "end": 168.23999999999998,
      "text": " And that's when I decided to switch roles and go more into an engineering side,",
      "tokens": [
        51564,
        400,
        300,
        311,
        562,
        286,
        3047,
        281,
        3679,
        9604,
        293,
        352,
        544,
        666,
        364,
        7043,
        1252,
        11,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1557005578344995,
      "compression_ratio": 1.5758928571428572,
      "no_speech_prob": 0.00044293756945990026
    },
    {
      "id": 37,
      "seek": 16824,
      "start": 168.24,
      "end": 172.48000000000002,
      "text": " rather than dabbling both engineering and dev rel at the same time.",
      "tokens": [
        50364,
        2831,
        813,
        274,
        10797,
        1688,
        1293,
        7043,
        293,
        1905,
        1039,
        412,
        264,
        912,
        565,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17675712222144718,
      "compression_ratio": 1.636,
      "no_speech_prob": 0.0013533629244193435
    },
    {
      "id": 38,
      "seek": 16824,
      "start": 172.48000000000002,
      "end": 177.0,
      "text": " And eventually I ended up landing a job at Trepa.",
      "tokens": [
        50576,
        400,
        4728,
        286,
        4590,
        493,
        11202,
        257,
        1691,
        412,
        8648,
        4306,
        13,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17675712222144718,
      "compression_ratio": 1.636,
      "no_speech_prob": 0.0013533629244193435
    },
    {
      "id": 39,
      "seek": 16824,
      "start": 177.0,
      "end": 184.12,
      "text": " And ever since, I think I joined here back in September and it has been a great time till now.",
      "tokens": [
        50802,
        400,
        1562,
        1670,
        11,
        286,
        519,
        286,
        6869,
        510,
        646,
        294,
        7216,
        293,
        309,
        575,
        668,
        257,
        869,
        565,
        4288,
        586,
        13,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17675712222144718,
      "compression_ratio": 1.636,
      "no_speech_prob": 0.0013533629244193435
    },
    {
      "id": 40,
      "seek": 16824,
      "start": 184.12,
      "end": 187.04000000000002,
      "text": " Perfect. That sounds great. I think you mentioned three major milestones.",
      "tokens": [
        51158,
        10246,
        13,
        663,
        3263,
        869,
        13,
        286,
        519,
        291,
        2835,
        1045,
        2563,
        42038,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17675712222144718,
      "compression_ratio": 1.636,
      "no_speech_prob": 0.0013533629244193435
    },
    {
      "id": 41,
      "seek": 16824,
      "start": 187.04000000000002,
      "end": 189.84,
      "text": " One which is working with the Foundation as an intern,",
      "tokens": [
        51304,
        1485,
        597,
        307,
        1364,
        365,
        264,
        10335,
        382,
        364,
        2154,
        11,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17675712222144718,
      "compression_ratio": 1.636,
      "no_speech_prob": 0.0013533629244193435
    },
    {
      "id": 42,
      "seek": 16824,
      "start": 189.84,
      "end": 193.28,
      "text": " then working at Helios as a dev rel advocate and then now at Trepa.",
      "tokens": [
        51444,
        550,
        1364,
        412,
        6128,
        2717,
        382,
        257,
        1905,
        1039,
        14608,
        293,
        550,
        586,
        412,
        8648,
        4306,
        13,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17675712222144718,
      "compression_ratio": 1.636,
      "no_speech_prob": 0.0013533629244193435
    },
    {
      "id": 43,
      "seek": 19328,
      "start": 193.32,
      "end": 198.28,
      "text": " Do you briefly want to touch up on your journey and your day-to-day at the Foundation and at Helios?",
      "tokens": [
        50366,
        1144,
        291,
        10515,
        528,
        281,
        2557,
        493,
        322,
        428,
        4671,
        293,
        428,
        786,
        12,
        1353,
        12,
        810,
        412,
        264,
        10335,
        293,
        412,
        6128,
        2717,
        30,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15463497764185855,
      "compression_ratio": 1.5665236051502145,
      "no_speech_prob": 0.0282718725502491
    },
    {
      "id": 44,
      "seek": 19328,
      "start": 198.28,
      "end": 209.84,
      "text": " So at Foundation, I did like a three-month internship where I used to mostly work on writing modules for Solana workshop.",
      "tokens": [
        50614,
        407,
        412,
        10335,
        11,
        286,
        630,
        411,
        257,
        1045,
        12,
        23534,
        16861,
        689,
        286,
        1143,
        281,
        5240,
        589,
        322,
        3579,
        16679,
        337,
        7026,
        2095,
        13541,
        13,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15463497764185855,
      "compression_ratio": 1.5665236051502145,
      "no_speech_prob": 0.0282718725502491
    },
    {
      "id": 45,
      "seek": 19328,
      "start": 209.84,
      "end": 211.36,
      "text": " Most of my time went into that.",
      "tokens": [
        51192,
        4534,
        295,
        452,
        565,
        1437,
        666,
        300,
        13,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15463497764185855,
      "compression_ratio": 1.5665236051502145,
      "no_speech_prob": 0.0282718725502491
    },
    {
      "id": 46,
      "seek": 19328,
      "start": 211.36,
      "end": 218.08,
      "text": " And after that, I took those workshops with the help of Vishal, which was also an intern at that time with me.",
      "tokens": [
        51268,
        400,
        934,
        300,
        11,
        286,
        1890,
        729,
        19162,
        365,
        264,
        854,
        295,
        36752,
        304,
        11,
        597,
        390,
        611,
        364,
        2154,
        412,
        300,
        565,
        365,
        385,
        13,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15463497764185855,
      "compression_ratio": 1.5665236051502145,
      "no_speech_prob": 0.0282718725502491
    },
    {
      "id": 47,
      "seek": 21808,
      "start": 218.08,
      "end": 223.96,
      "text": " And at Helios, my work had two pillars.",
      "tokens": [
        50364,
        400,
        412,
        6128,
        2717,
        11,
        452,
        589,
        632,
        732,
        26729,
        13,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13455282923686934,
      "compression_ratio": 1.52803738317757,
      "no_speech_prob": 0.00907104928046465
    },
    {
      "id": 48,
      "seek": 21808,
      "start": 223.96,
      "end": 234.16000000000003,
      "text": " One was the dev rel side of things where I would talk with our customers or users at Helios and help them resolve any issues that they had.",
      "tokens": [
        50658,
        1485,
        390,
        264,
        1905,
        1039,
        1252,
        295,
        721,
        689,
        286,
        576,
        751,
        365,
        527,
        4581,
        420,
        5022,
        412,
        6128,
        2717,
        293,
        854,
        552,
        14151,
        604,
        2663,
        300,
        436,
        632,
        13,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13455282923686934,
      "compression_ratio": 1.52803738317757,
      "no_speech_prob": 0.00907104928046465
    },
    {
      "id": 49,
      "seek": 21808,
      "start": 234.16000000000003,
      "end": 242.64000000000001,
      "text": " And the second fold was basically helping them indirectly via updating the SDK, citing the documentation.",
      "tokens": [
        51168,
        400,
        264,
        1150,
        4860,
        390,
        1936,
        4315,
        552,
        37779,
        5766,
        25113,
        264,
        37135,
        11,
        48749,
        264,
        14333,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13455282923686934,
      "compression_ratio": 1.52803738317757,
      "no_speech_prob": 0.00907104928046465
    },
    {
      "id": 50,
      "seek": 21808,
      "start": 242.64000000000001,
      "end": 246.32000000000002,
      "text": " So that was my day-to-day life at Helios.",
      "tokens": [
        51592,
        407,
        300,
        390,
        452,
        786,
        12,
        1353,
        12,
        810,
        993,
        412,
        6128,
        2717,
        13,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13455282923686934,
      "compression_ratio": 1.52803738317757,
      "no_speech_prob": 0.00907104928046465
    },
    {
      "id": 51,
      "seek": 24632,
      "start": 246.32,
      "end": 258.84,
      "text": " And right now at Trepa, I mostly handle everything related to blockchain, the integration at the backend and anything that relates to how Trepa works internally.",
      "tokens": [
        50364,
        400,
        558,
        586,
        412,
        8648,
        4306,
        11,
        286,
        5240,
        4813,
        1203,
        4077,
        281,
        17176,
        11,
        264,
        10980,
        412,
        264,
        38087,
        293,
        1340,
        300,
        16155,
        281,
        577,
        8648,
        4306,
        1985,
        19501,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25068058157866857,
      "compression_ratio": 1.7126436781609196,
      "no_speech_prob": 0.0030420818366110325
    },
    {
      "id": 52,
      "seek": 24632,
      "start": 258.84,
      "end": 260.2,
      "text": " I work on that.",
      "tokens": [
        50990,
        286,
        589,
        322,
        300,
        13,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25068058157866857,
      "compression_ratio": 1.7126436781609196,
      "no_speech_prob": 0.0030420818366110325
    },
    {
      "id": 53,
      "seek": 24632,
      "start": 260.2,
      "end": 263.64,
      "text": " Correct. That sounds perfect. Let's dive into your Trepa journey now.",
      "tokens": [
        51058,
        12753,
        13,
        663,
        3263,
        2176,
        13,
        961,
        311,
        9192,
        666,
        428,
        8648,
        4306,
        4671,
        586,
        13,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25068058157866857,
      "compression_ratio": 1.7126436781609196,
      "no_speech_prob": 0.0030420818366110325
    },
    {
      "id": 54,
      "seek": 24632,
      "start": 263.64,
      "end": 268.32,
      "text": " Very interesting, you mentioned a term, precision predictive markets.",
      "tokens": [
        51230,
        4372,
        1880,
        11,
        291,
        2835,
        257,
        1433,
        11,
        18356,
        35521,
        8383,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25068058157866857,
      "compression_ratio": 1.7126436781609196,
      "no_speech_prob": 0.0030420818366110325
    },
    {
      "id": 55,
      "seek": 24632,
      "start": 268.32,
      "end": 272.84,
      "text": " Is this like a new term or is it like a common term that's, you know, I only know predictive markets, prediction markets for now.",
      "tokens": [
        51464,
        1119,
        341,
        411,
        257,
        777,
        1433,
        420,
        307,
        309,
        411,
        257,
        2689,
        1433,
        300,
        311,
        11,
        291,
        458,
        11,
        286,
        787,
        458,
        35521,
        8383,
        11,
        17630,
        8383,
        337,
        586,
        13,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25068058157866857,
      "compression_ratio": 1.7126436781609196,
      "no_speech_prob": 0.0030420818366110325
    },
    {
      "id": 56,
      "seek": 27284,
      "start": 272.84,
      "end": 277.2,
      "text": " So we're trying to build a new primitive in the prediction market space.",
      "tokens": [
        50364,
        407,
        321,
        434,
        1382,
        281,
        1322,
        257,
        777,
        28540,
        294,
        264,
        17630,
        2142,
        1901,
        13,
        50582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09631700949235396,
      "compression_ratio": 1.639269406392694,
      "no_speech_prob": 0.012220805510878563
    },
    {
      "id": 57,
      "seek": 27284,
      "start": 277.2,
      "end": 282.32,
      "text": " And by precision, we simply mean that you predict a real world number.",
      "tokens": [
        50582,
        400,
        538,
        18356,
        11,
        321,
        2935,
        914,
        300,
        291,
        6069,
        257,
        957,
        1002,
        1230,
        13,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09631700949235396,
      "compression_ratio": 1.639269406392694,
      "no_speech_prob": 0.012220805510878563
    },
    {
      "id": 58,
      "seek": 27284,
      "start": 282.32,
      "end": 292.32,
      "text": " So instead of saying yes or no, up or down, you actually put in an exact number or somewhat closer to what you feel the outcome would be.",
      "tokens": [
        50838,
        407,
        2602,
        295,
        1566,
        2086,
        420,
        572,
        11,
        493,
        420,
        760,
        11,
        291,
        767,
        829,
        294,
        364,
        1900,
        1230,
        420,
        8344,
        4966,
        281,
        437,
        291,
        841,
        264,
        9700,
        576,
        312,
        13,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09631700949235396,
      "compression_ratio": 1.639269406392694,
      "no_speech_prob": 0.012220805510878563
    },
    {
      "id": 59,
      "seek": 27284,
      "start": 292.32,
      "end": 297.32,
      "text": " So it's not something like you need to actually get this exact number to win.",
      "tokens": [
        51338,
        407,
        309,
        311,
        406,
        746,
        411,
        291,
        643,
        281,
        767,
        483,
        341,
        1900,
        1230,
        281,
        1942,
        13,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09631700949235396,
      "compression_ratio": 1.639269406392694,
      "no_speech_prob": 0.012220805510878563
    },
    {
      "id": 60,
      "seek": 29732,
      "start": 297.32,
      "end": 299.71999999999997,
      "text": " It's like how close you are to the outcome.",
      "tokens": [
        50364,
        467,
        311,
        411,
        577,
        1998,
        291,
        366,
        281,
        264,
        9700,
        13,
        50484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19592007594322092,
      "compression_ratio": 1.6054421768707483,
      "no_speech_prob": 0.22625672817230225
    },
    {
      "id": 61,
      "seek": 29732,
      "start": 299.71999999999997,
      "end": 303.84,
      "text": " Your rewards are essentially calculated in that way.",
      "tokens": [
        50484,
        2260,
        17203,
        366,
        4476,
        15598,
        294,
        300,
        636,
        13,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19592007594322092,
      "compression_ratio": 1.6054421768707483,
      "no_speech_prob": 0.22625672817230225
    },
    {
      "id": 62,
      "seek": 29732,
      "start": 303.84,
      "end": 309.04,
      "text": " Correct. So if I go to Polymarket or Calsea, I can only select if so above 150 or below 150.",
      "tokens": [
        50690,
        12753,
        13,
        407,
        498,
        286,
        352,
        281,
        18553,
        16414,
        420,
        3511,
        17531,
        11,
        286,
        393,
        787,
        3048,
        498,
        370,
        3673,
        8451,
        420,
        2507,
        8451,
        13,
        50950
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19592007594322092,
      "compression_ratio": 1.6054421768707483,
      "no_speech_prob": 0.22625672817230225
    },
    {
      "id": 63,
      "seek": 29732,
      "start": 309.04,
      "end": 315.15999999999997,
      "text": " But on Trepa, I can predict a number, let's say 149 and my payout will be based on how close I am to the final number.",
      "tokens": [
        50950,
        583,
        322,
        8648,
        4306,
        11,
        286,
        393,
        6069,
        257,
        1230,
        11,
        718,
        311,
        584,
        3499,
        24,
        293,
        452,
        1689,
        346,
        486,
        312,
        2361,
        322,
        577,
        1998,
        286,
        669,
        281,
        264,
        2572,
        1230,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19592007594322092,
      "compression_ratio": 1.6054421768707483,
      "no_speech_prob": 0.22625672817230225
    },
    {
      "id": 64,
      "seek": 29732,
      "start": 315.15999999999997,
      "end": 315.8,
      "text": " Is that right?",
      "tokens": [
        51256,
        1119,
        300,
        558,
        30,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19592007594322092,
      "compression_ratio": 1.6054421768707483,
      "no_speech_prob": 0.22625672817230225
    },
    {
      "id": 65,
      "seek": 29732,
      "start": 315.8,
      "end": 326.15999999999997,
      "text": " Yeah. So you just need to enter like whatever number you believe or you're convicted that, OK, I want to put in this number, let's say $149 for Sol.",
      "tokens": [
        51288,
        865,
        13,
        407,
        291,
        445,
        643,
        281,
        3242,
        411,
        2035,
        1230,
        291,
        1697,
        420,
        291,
        434,
        26942,
        300,
        11,
        2264,
        11,
        286,
        528,
        281,
        829,
        294,
        341,
        1230,
        11,
        718,
        311,
        584,
        1848,
        7271,
        24,
        337,
        7026,
        13,
        51806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19592007594322092,
      "compression_ratio": 1.6054421768707483,
      "no_speech_prob": 0.22625672817230225
    },
    {
      "id": 66,
      "seek": 32616,
      "start": 326.20000000000005,
      "end": 335.96000000000004,
      "text": " I know it's not the case right now, but let's say, let's say you put in $149 for Sol and you also put in some stake.",
      "tokens": [
        50366,
        286,
        458,
        309,
        311,
        406,
        264,
        1389,
        558,
        586,
        11,
        457,
        718,
        311,
        584,
        11,
        718,
        311,
        584,
        291,
        829,
        294,
        1848,
        7271,
        24,
        337,
        7026,
        293,
        291,
        611,
        829,
        294,
        512,
        10407,
        13,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15333883261974948,
      "compression_ratio": 1.4331550802139037,
      "no_speech_prob": 0.007060160394757986
    },
    {
      "id": 67,
      "seek": 32616,
      "start": 335.96000000000004,
      "end": 346.84000000000003,
      "text": " And at the end, what we do is we at Trepa, we have a accuracy weighted mechanism in a perimitual pool system.",
      "tokens": [
        50854,
        400,
        412,
        264,
        917,
        11,
        437,
        321,
        360,
        307,
        321,
        412,
        8648,
        4306,
        11,
        321,
        362,
        257,
        14170,
        32807,
        7513,
        294,
        257,
        680,
        332,
        270,
        901,
        7005,
        1185,
        13,
        51398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15333883261974948,
      "compression_ratio": 1.4331550802139037,
      "no_speech_prob": 0.007060160394757986
    },
    {
      "id": 68,
      "seek": 32616,
      "start": 346.84000000000003,
      "end": 349.28000000000003,
      "text": " I'll just break it down in simpler terms.",
      "tokens": [
        51398,
        286,
        603,
        445,
        1821,
        309,
        760,
        294,
        18587,
        2115,
        13,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15333883261974948,
      "compression_ratio": 1.4331550802139037,
      "no_speech_prob": 0.007060160394757986
    },
    {
      "id": 69,
      "seek": 34928,
      "start": 349.32,
      "end": 358.91999999999996,
      "text": " So by perimitual, what we mean is whoever who has entered into this pool and stake some money, whatever, if you win, you get from that pool itself.",
      "tokens": [
        50366,
        407,
        538,
        680,
        332,
        270,
        901,
        11,
        437,
        321,
        914,
        307,
        11387,
        567,
        575,
        9065,
        666,
        341,
        7005,
        293,
        10407,
        512,
        1460,
        11,
        2035,
        11,
        498,
        291,
        1942,
        11,
        291,
        483,
        490,
        300,
        7005,
        2564,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10992825031280518,
      "compression_ratio": 1.6269430051813472,
      "no_speech_prob": 0.09321056306362152
    },
    {
      "id": 70,
      "seek": 34928,
      "start": 358.91999999999996,
      "end": 363.15999999999997,
      "text": " So you're essentially betting against everyone who is inside that pool.",
      "tokens": [
        50846,
        407,
        291,
        434,
        4476,
        34246,
        1970,
        1518,
        567,
        307,
        1854,
        300,
        7005,
        13,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10992825031280518,
      "compression_ratio": 1.6269430051813472,
      "no_speech_prob": 0.09321056306362152
    },
    {
      "id": 71,
      "seek": 34928,
      "start": 363.15999999999997,
      "end": 365.23999999999995,
      "text": " So that's how you get rewarded.",
      "tokens": [
        51058,
        407,
        300,
        311,
        577,
        291,
        483,
        29105,
        13,
        51162
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10992825031280518,
      "compression_ratio": 1.6269430051813472,
      "no_speech_prob": 0.09321056306362152
    },
    {
      "id": 72,
      "seek": 34928,
      "start": 365.23999999999995,
      "end": 369.55999999999995,
      "text": " And the amount that you get rewarded is based on three things.",
      "tokens": [
        51162,
        400,
        264,
        2372,
        300,
        291,
        483,
        29105,
        307,
        2361,
        322,
        1045,
        721,
        13,
        51378
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10992825031280518,
      "compression_ratio": 1.6269430051813472,
      "no_speech_prob": 0.09321056306362152
    },
    {
      "id": 73,
      "seek": 36956,
      "start": 369.56,
      "end": 371.68,
      "text": " One is how accurate you are.",
      "tokens": [
        50364,
        1485,
        307,
        577,
        8559,
        291,
        366,
        13,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14488011410361842,
      "compression_ratio": 1.7537688442211055,
      "no_speech_prob": 0.48875051736831665
    },
    {
      "id": 74,
      "seek": 36956,
      "start": 371.68,
      "end": 379.6,
      "text": " So we get a normalized error after the outcome is reached.",
      "tokens": [
        50470,
        407,
        321,
        483,
        257,
        48704,
        6713,
        934,
        264,
        9700,
        307,
        6488,
        13,
        50866
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14488011410361842,
      "compression_ratio": 1.7537688442211055,
      "no_speech_prob": 0.48875051736831665
    },
    {
      "id": 75,
      "seek": 36956,
      "start": 379.6,
      "end": 383.28000000000003,
      "text": " And after the accuracy, we look into how much stake you put in.",
      "tokens": [
        50866,
        400,
        934,
        264,
        14170,
        11,
        321,
        574,
        666,
        577,
        709,
        10407,
        291,
        829,
        294,
        13,
        51050
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14488011410361842,
      "compression_ratio": 1.7537688442211055,
      "no_speech_prob": 0.48875051736831665
    },
    {
      "id": 76,
      "seek": 36956,
      "start": 383.28000000000003,
      "end": 389.48,
      "text": " So if you put in a higher stake and you were more accurate, then you get more payout.",
      "tokens": [
        51050,
        407,
        498,
        291,
        829,
        294,
        257,
        2946,
        10407,
        293,
        291,
        645,
        544,
        8559,
        11,
        550,
        291,
        483,
        544,
        1689,
        346,
        13,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14488011410361842,
      "compression_ratio": 1.7537688442211055,
      "no_speech_prob": 0.48875051736831665
    },
    {
      "id": 77,
      "seek": 36956,
      "start": 389.48,
      "end": 392.64,
      "text": " And the last thing is you also have a time edge.",
      "tokens": [
        51360,
        400,
        264,
        1036,
        551,
        307,
        291,
        611,
        362,
        257,
        565,
        4691,
        13,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14488011410361842,
      "compression_ratio": 1.7537688442211055,
      "no_speech_prob": 0.48875051736831665
    },
    {
      "id": 78,
      "seek": 36956,
      "start": 392.64,
      "end": 397.4,
      "text": " So if you predicted quite early, then you also have that edge.",
      "tokens": [
        51518,
        407,
        498,
        291,
        19147,
        1596,
        2440,
        11,
        550,
        291,
        611,
        362,
        300,
        4691,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14488011410361842,
      "compression_ratio": 1.7537688442211055,
      "no_speech_prob": 0.48875051736831665
    },
    {
      "id": 79,
      "seek": 39740,
      "start": 397.4,
      "end": 401.32,
      "text": " So it's a function of accuracy, your stake and time.",
      "tokens": [
        50364,
        407,
        309,
        311,
        257,
        2445,
        295,
        14170,
        11,
        428,
        10407,
        293,
        565,
        13,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16121190723619963,
      "compression_ratio": 1.5659574468085107,
      "no_speech_prob": 0.00937541201710701
    },
    {
      "id": 80,
      "seek": 39740,
      "start": 401.32,
      "end": 407.32,
      "text": " So these three things involved in a complex calculation decides your payout.",
      "tokens": [
        50560,
        407,
        613,
        1045,
        721,
        3288,
        294,
        257,
        3997,
        17108,
        14898,
        428,
        1689,
        346,
        13,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16121190723619963,
      "compression_ratio": 1.5659574468085107,
      "no_speech_prob": 0.00937541201710701
    },
    {
      "id": 81,
      "seek": 39740,
      "start": 407.32,
      "end": 410.28,
      "text": " And it's a very convex payout curve.",
      "tokens": [
        50860,
        400,
        309,
        311,
        257,
        588,
        42432,
        1689,
        346,
        7605,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16121190723619963,
      "compression_ratio": 1.5659574468085107,
      "no_speech_prob": 0.00937541201710701
    },
    {
      "id": 82,
      "seek": 39740,
      "start": 410.28,
      "end": 416.96,
      "text": " So it could somehow if you're very accurate, it feels like a jackpot because you were the closest one.",
      "tokens": [
        51008,
        407,
        309,
        727,
        6063,
        498,
        291,
        434,
        588,
        8559,
        11,
        309,
        3417,
        411,
        257,
        7109,
        17698,
        570,
        291,
        645,
        264,
        13699,
        472,
        13,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16121190723619963,
      "compression_ratio": 1.5659574468085107,
      "no_speech_prob": 0.00937541201710701
    },
    {
      "id": 83,
      "seek": 39740,
      "start": 416.96,
      "end": 418.52,
      "text": " Got it. That makes sense.",
      "tokens": [
        51342,
        5803,
        309,
        13,
        663,
        1669,
        2020,
        13,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16121190723619963,
      "compression_ratio": 1.5659574468085107,
      "no_speech_prob": 0.00937541201710701
    },
    {
      "id": 84,
      "seek": 39740,
      "start": 418.52,
      "end": 422.4,
      "text": " I can already think of a few challenges in building something like this.",
      "tokens": [
        51420,
        286,
        393,
        1217,
        519,
        295,
        257,
        1326,
        4759,
        294,
        2390,
        746,
        411,
        341,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16121190723619963,
      "compression_ratio": 1.5659574468085107,
      "no_speech_prob": 0.00937541201710701
    },
    {
      "id": 85,
      "seek": 42240,
      "start": 422.47999999999996,
      "end": 426.2,
      "text": " For example, on a polymarket or a Kashi, I think I mean B2B.",
      "tokens": [
        50368,
        1171,
        1365,
        11,
        322,
        257,
        6754,
        16414,
        420,
        257,
        591,
        15612,
        11,
        286,
        519,
        286,
        914,
        363,
        17,
        33,
        13,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 86,
      "seek": 42240,
      "start": 426.2,
      "end": 428.59999999999997,
      "text": " So you're essentially trading against someone else.",
      "tokens": [
        50554,
        407,
        291,
        434,
        4476,
        9529,
        1970,
        1580,
        1646,
        13,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 87,
      "seek": 42240,
      "start": 428.59999999999997,
      "end": 433.28,
      "text": " You both get some sort of stocks which eventually land up to a zero or a one.",
      "tokens": [
        50674,
        509,
        1293,
        483,
        512,
        1333,
        295,
        12966,
        597,
        4728,
        2117,
        493,
        281,
        257,
        4018,
        420,
        257,
        472,
        13,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 88,
      "seek": 42240,
      "start": 433.28,
      "end": 435.4,
      "text": " So fairly predictable.",
      "tokens": [
        50908,
        407,
        6457,
        27737,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 89,
      "seek": 42240,
      "start": 435.4,
      "end": 441.88,
      "text": " One very first sort of contention that I get is what if I am the first one in the market?",
      "tokens": [
        51014,
        1485,
        588,
        700,
        1333,
        295,
        660,
        1251,
        300,
        286,
        483,
        307,
        437,
        498,
        286,
        669,
        264,
        700,
        472,
        294,
        264,
        2142,
        30,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 90,
      "seek": 42240,
      "start": 441.88,
      "end": 445.4,
      "text": " I put in a thousand dollars worth of stake.",
      "tokens": [
        51338,
        286,
        829,
        294,
        257,
        4714,
        3808,
        3163,
        295,
        10407,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 91,
      "seek": 42240,
      "start": 445.4,
      "end": 448.15999999999997,
      "text": " I predicted a price of 149.",
      "tokens": [
        51514,
        286,
        19147,
        257,
        3218,
        295,
        3499,
        24,
        13,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 92,
      "seek": 42240,
      "start": 448.15999999999997,
      "end": 452.23999999999995,
      "text": " And let's say it landed at 150 and no one else ended up participating in this market.",
      "tokens": [
        51652,
        400,
        718,
        311,
        584,
        309,
        15336,
        412,
        8451,
        293,
        572,
        472,
        1646,
        4590,
        493,
        13950,
        294,
        341,
        2142,
        13,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2581583261489868,
      "compression_ratio": 1.589655172413793,
      "no_speech_prob": 0.30149203538894653
    },
    {
      "id": 93,
      "seek": 45224,
      "start": 452.24,
      "end": 456.24,
      "text": " So what happens here is Trepa.",
      "tokens": [
        50364,
        407,
        437,
        2314,
        510,
        307,
        8648,
        4306,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 94,
      "seek": 45224,
      "start": 456.24,
      "end": 458.32,
      "text": " So you're not betting against us.",
      "tokens": [
        50564,
        407,
        291,
        434,
        406,
        34246,
        1970,
        505,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 95,
      "seek": 45224,
      "start": 458.32,
      "end": 461.92,
      "text": " If you were the only one in the pool, obviously you'll get the money back.",
      "tokens": [
        50668,
        759,
        291,
        645,
        264,
        787,
        472,
        294,
        264,
        7005,
        11,
        2745,
        291,
        603,
        483,
        264,
        1460,
        646,
        13,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 96,
      "seek": 45224,
      "start": 461.92,
      "end": 466.32,
      "text": " We won't add any we won't add any bets from our side.",
      "tokens": [
        50848,
        492,
        1582,
        380,
        909,
        604,
        321,
        1582,
        380,
        909,
        604,
        39922,
        490,
        527,
        1252,
        13,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 97,
      "seek": 45224,
      "start": 466.32,
      "end": 468.8,
      "text": " Or it's not like you're playing against us.",
      "tokens": [
        51068,
        1610,
        309,
        311,
        406,
        411,
        291,
        434,
        2433,
        1970,
        505,
        13,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 98,
      "seek": 45224,
      "start": 468.8,
      "end": 473.52,
      "text": " It just who has stakes in the pool is the is the one who you bet against.",
      "tokens": [
        51192,
        467,
        445,
        567,
        575,
        28429,
        294,
        264,
        7005,
        307,
        264,
        307,
        264,
        472,
        567,
        291,
        778,
        1970,
        13,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 99,
      "seek": 45224,
      "start": 473.52,
      "end": 474.6,
      "text": " Correct. So it might happen.",
      "tokens": [
        51428,
        12753,
        13,
        407,
        309,
        1062,
        1051,
        13,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 100,
      "seek": 45224,
      "start": 474.6,
      "end": 476.56,
      "text": " I might be extremely precisely correct.",
      "tokens": [
        51482,
        286,
        1062,
        312,
        4664,
        13402,
        3006,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 101,
      "seek": 45224,
      "start": 476.56,
      "end": 479.64,
      "text": " But if no one else participated in the market, I'll just get back my money.",
      "tokens": [
        51580,
        583,
        498,
        572,
        472,
        1646,
        17978,
        294,
        264,
        2142,
        11,
        286,
        603,
        445,
        483,
        646,
        452,
        1460,
        13,
        51734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22394417982835035,
      "compression_ratio": 1.7404580152671756,
      "no_speech_prob": 0.0007588392472825944
    },
    {
      "id": 102,
      "seek": 47964,
      "start": 480.47999999999996,
      "end": 481.47999999999996,
      "text": " Yeah.",
      "tokens": [
        50406,
        865,
        13,
        50456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 103,
      "seek": 47964,
      "start": 481.47999999999996,
      "end": 482.47999999999996,
      "text": " Got it.",
      "tokens": [
        50456,
        5803,
        309,
        13,
        50506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 104,
      "seek": 47964,
      "start": 482.47999999999996,
      "end": 484.47999999999996,
      "text": " Which might lead to a bunch of chicken and egg challenges.",
      "tokens": [
        50506,
        3013,
        1062,
        1477,
        281,
        257,
        3840,
        295,
        4662,
        293,
        3777,
        4759,
        13,
        50606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 105,
      "seek": 47964,
      "start": 484.47999999999996,
      "end": 488.0,
      "text": " Right. If you don't have enough fingers, then you know, there's not enough incentive for",
      "tokens": [
        50606,
        1779,
        13,
        759,
        291,
        500,
        380,
        362,
        1547,
        7350,
        11,
        550,
        291,
        458,
        11,
        456,
        311,
        406,
        1547,
        22346,
        337,
        50782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 106,
      "seek": 47964,
      "start": 488.0,
      "end": 489.8,
      "text": " someone to play.",
      "tokens": [
        50782,
        1580,
        281,
        862,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 107,
      "seek": 47964,
      "start": 489.8,
      "end": 493.68,
      "text": " So a little more of I guess questions around marketing.",
      "tokens": [
        50872,
        407,
        257,
        707,
        544,
        295,
        286,
        2041,
        1651,
        926,
        6370,
        13,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 108,
      "seek": 47964,
      "start": 493.68,
      "end": 497.91999999999996,
      "text": " Is there anything specific around, you know, how you are trying to challenge this, tackle",
      "tokens": [
        51066,
        1119,
        456,
        1340,
        2685,
        926,
        11,
        291,
        458,
        11,
        577,
        291,
        366,
        1382,
        281,
        3430,
        341,
        11,
        14896,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 109,
      "seek": 47964,
      "start": 497.91999999999996,
      "end": 501.2,
      "text": " this specific challenge of you probably need at least 100 people participating on a market",
      "tokens": [
        51278,
        341,
        2685,
        3430,
        295,
        291,
        1391,
        643,
        412,
        1935,
        2319,
        561,
        13950,
        322,
        257,
        2142,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 110,
      "seek": 47964,
      "start": 501.2,
      "end": 502.2,
      "text": " for it to be liquid?",
      "tokens": [
        51442,
        337,
        309,
        281,
        312,
        6553,
        30,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 111,
      "seek": 47964,
      "start": 502.2,
      "end": 505.28,
      "text": " Are you doing market making yourself participating in markets yourself?",
      "tokens": [
        51492,
        2014,
        291,
        884,
        2142,
        1455,
        1803,
        13950,
        294,
        8383,
        1803,
        30,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 112,
      "seek": 47964,
      "start": 505.28,
      "end": 507.64,
      "text": " Or are you getting other market makers?",
      "tokens": [
        51646,
        1610,
        366,
        291,
        1242,
        661,
        2142,
        19323,
        30,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3231083884168027,
      "compression_ratio": 1.767741935483871,
      "no_speech_prob": 0.20854824781417847
    },
    {
      "id": 113,
      "seek": 50764,
      "start": 507.71999999999997,
      "end": 512.28,
      "text": " You know, has it been tough to convince market makers who are already on products like",
      "tokens": [
        50368,
        509,
        458,
        11,
        575,
        309,
        668,
        4930,
        281,
        13447,
        2142,
        19323,
        567,
        366,
        1217,
        322,
        3383,
        411,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2885320326861213,
      "compression_ratio": 1.611336032388664,
      "no_speech_prob": 0.016906950622797012
    },
    {
      "id": 114,
      "seek": 50764,
      "start": 512.28,
      "end": 516.28,
      "text": " Kalsi and Polymarket to come over to, you know, a new primitive like this?",
      "tokens": [
        50596,
        591,
        1124,
        72,
        293,
        18553,
        16414,
        281,
        808,
        670,
        281,
        11,
        291,
        458,
        11,
        257,
        777,
        28540,
        411,
        341,
        30,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2885320326861213,
      "compression_ratio": 1.611336032388664,
      "no_speech_prob": 0.016906950622797012
    },
    {
      "id": 115,
      "seek": 50764,
      "start": 516.28,
      "end": 522.68,
      "text": " So we don't have any market meetings currently, just you play with whoever predicts in the",
      "tokens": [
        50796,
        407,
        321,
        500,
        380,
        362,
        604,
        2142,
        8410,
        4362,
        11,
        445,
        291,
        862,
        365,
        11387,
        6069,
        82,
        294,
        264,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2885320326861213,
      "compression_ratio": 1.611336032388664,
      "no_speech_prob": 0.016906950622797012
    },
    {
      "id": 116,
      "seek": 50764,
      "start": 522.68,
      "end": 530.24,
      "text": " pool and then this 50 percent of the stake made stake weighted median gets to be the",
      "tokens": [
        51116,
        7005,
        293,
        550,
        341,
        2625,
        3043,
        295,
        264,
        10407,
        1027,
        10407,
        32807,
        26779,
        2170,
        281,
        312,
        264,
        51494
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2885320326861213,
      "compression_ratio": 1.611336032388664,
      "no_speech_prob": 0.016906950622797012
    },
    {
      "id": 117,
      "seek": 50764,
      "start": 530.24,
      "end": 531.24,
      "text": " winner.",
      "tokens": [
        51494,
        8507,
        13,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2885320326861213,
      "compression_ratio": 1.611336032388664,
      "no_speech_prob": 0.016906950622797012
    },
    {
      "id": 118,
      "seek": 50764,
      "start": 531.24,
      "end": 534.12,
      "text": " So it's not just one winner who's the most accurate.",
      "tokens": [
        51544,
        407,
        309,
        311,
        406,
        445,
        472,
        8507,
        567,
        311,
        264,
        881,
        8559,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2885320326861213,
      "compression_ratio": 1.611336032388664,
      "no_speech_prob": 0.016906950622797012
    },
    {
      "id": 119,
      "seek": 53412,
      "start": 534.12,
      "end": 540.16,
      "text": " What we do is we order them based on their accuracy and then we get the cumulative stake",
      "tokens": [
        50364,
        708,
        321,
        360,
        307,
        321,
        1668,
        552,
        2361,
        322,
        641,
        14170,
        293,
        550,
        321,
        483,
        264,
        38379,
        10407,
        50666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 120,
      "seek": 53412,
      "start": 540.16,
      "end": 547.68,
      "text": " and whoever is the like anyone about the median 50 percent stake weight would be the winner",
      "tokens": [
        50666,
        293,
        11387,
        307,
        264,
        411,
        2878,
        466,
        264,
        26779,
        2625,
        3043,
        10407,
        3364,
        576,
        312,
        264,
        8507,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 121,
      "seek": 53412,
      "start": 547.68,
      "end": 551.12,
      "text": " and then the payout will be calculated after that.",
      "tokens": [
        51042,
        293,
        550,
        264,
        1689,
        346,
        486,
        312,
        15598,
        934,
        300,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 122,
      "seek": 53412,
      "start": 551.12,
      "end": 555.0,
      "text": " And yeah, there is no market making involved at this point right now.",
      "tokens": [
        51214,
        400,
        1338,
        11,
        456,
        307,
        572,
        2142,
        1455,
        3288,
        412,
        341,
        935,
        558,
        586,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 123,
      "seek": 53412,
      "start": 555.0,
      "end": 556.0,
      "text": " Got it.",
      "tokens": [
        51408,
        5803,
        309,
        13,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 124,
      "seek": 53412,
      "start": 556.0,
      "end": 557.0,
      "text": " Makes sense.",
      "tokens": [
        51458,
        25245,
        2020,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 125,
      "seek": 53412,
      "start": 557.0,
      "end": 561.96,
      "text": " And when can I predict like 149.1111 something like that?",
      "tokens": [
        51508,
        400,
        562,
        393,
        286,
        6069,
        411,
        3499,
        24,
        13,
        5348,
        5348,
        746,
        411,
        300,
        30,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23277924985301737,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.03181156516075134
    },
    {
      "id": 126,
      "seek": 56196,
      "start": 562.36,
      "end": 567.44,
      "text": " When we create a pool on our platform, we also set the value of precision.",
      "tokens": [
        50384,
        1133,
        321,
        1884,
        257,
        7005,
        322,
        527,
        3663,
        11,
        321,
        611,
        992,
        264,
        2158,
        295,
        18356,
        13,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 127,
      "seek": 56196,
      "start": 567.44,
      "end": 573.6800000000001,
      "text": " So we set the number of decimals you can predict to because we don't want any mathematical",
      "tokens": [
        50638,
        407,
        321,
        992,
        264,
        1230,
        295,
        979,
        332,
        1124,
        291,
        393,
        6069,
        281,
        570,
        321,
        500,
        380,
        528,
        604,
        18894,
        50950
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 128,
      "seek": 56196,
      "start": 573.6800000000001,
      "end": 576.52,
      "text": " issue at the end or the client side.",
      "tokens": [
        50950,
        2734,
        412,
        264,
        917,
        420,
        264,
        6423,
        1252,
        13,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 129,
      "seek": 56196,
      "start": 576.52,
      "end": 578.64,
      "text": " It does not mean that you don't get to be accurate.",
      "tokens": [
        51092,
        467,
        775,
        406,
        914,
        300,
        291,
        500,
        380,
        483,
        281,
        312,
        8559,
        13,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 130,
      "seek": 56196,
      "start": 578.64,
      "end": 584.0,
      "text": " It's just there so that you don't end up putting seven or six decimals at the end of your",
      "tokens": [
        51198,
        467,
        311,
        445,
        456,
        370,
        300,
        291,
        500,
        380,
        917,
        493,
        3372,
        3407,
        420,
        2309,
        979,
        332,
        1124,
        412,
        264,
        917,
        295,
        428,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 131,
      "seek": 56196,
      "start": 584.0,
      "end": 585.0,
      "text": " number.",
      "tokens": [
        51466,
        1230,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 132,
      "seek": 56196,
      "start": 585.0,
      "end": 588.32,
      "text": " So it highly depends on the value that you're predicting.",
      "tokens": [
        51516,
        407,
        309,
        5405,
        5946,
        322,
        264,
        2158,
        300,
        291,
        434,
        32884,
        13,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.129660964012146,
      "compression_ratio": 1.7521367521367521,
      "no_speech_prob": 0.028243424370884895
    },
    {
      "id": 133,
      "seek": 58832,
      "start": 588.36,
      "end": 594.88,
      "text": " So let's say you're predicting population data or GDP, which can be a very big number,",
      "tokens": [
        50366,
        407,
        718,
        311,
        584,
        291,
        434,
        32884,
        4415,
        1412,
        420,
        19599,
        11,
        597,
        393,
        312,
        257,
        588,
        955,
        1230,
        11,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 134,
      "seek": 58832,
      "start": 594.88,
      "end": 595.88,
      "text": " right?",
      "tokens": [
        50692,
        558,
        30,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 135,
      "seek": 58832,
      "start": 595.88,
      "end": 601.5200000000001,
      "text": " So we have steps added, which could make sure that you just predict like four billion or",
      "tokens": [
        50742,
        407,
        321,
        362,
        4439,
        3869,
        11,
        597,
        727,
        652,
        988,
        300,
        291,
        445,
        6069,
        411,
        1451,
        5218,
        420,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 136,
      "seek": 58832,
      "start": 601.5200000000001,
      "end": 603.48,
      "text": " four point one billion or four point two billion.",
      "tokens": [
        51024,
        1451,
        935,
        472,
        5218,
        420,
        1451,
        935,
        732,
        5218,
        13,
        51122
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 137,
      "seek": 58832,
      "start": 603.48,
      "end": 608.0,
      "text": " You don't actually enter a very big number instead.",
      "tokens": [
        51122,
        509,
        500,
        380,
        767,
        3242,
        257,
        588,
        955,
        1230,
        2602,
        13,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 138,
      "seek": 58832,
      "start": 608.0,
      "end": 609.6,
      "text": " And similarly for sole price.",
      "tokens": [
        51348,
        400,
        14138,
        337,
        12321,
        3218,
        13,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 139,
      "seek": 58832,
      "start": 609.6,
      "end": 613.5600000000001,
      "text": " So let's say for Solana, we I think have like two decimal places.",
      "tokens": [
        51428,
        407,
        718,
        311,
        584,
        337,
        7026,
        2095,
        11,
        321,
        286,
        519,
        362,
        411,
        732,
        26601,
        3190,
        13,
        51626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 140,
      "seek": 58832,
      "start": 613.5600000000001,
      "end": 617.08,
      "text": " So you can predict 140.62.",
      "tokens": [
        51626,
        407,
        291,
        393,
        6069,
        21548,
        13,
        28052,
        13,
        51802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20202302065762606,
      "compression_ratio": 1.6411290322580645,
      "no_speech_prob": 0.07077694684267044
    },
    {
      "id": 141,
      "seek": 61708,
      "start": 617.08,
      "end": 621.0400000000001,
      "text": " And for Bitcoin, we don't have that much precision because it's a very big numbers.",
      "tokens": [
        50364,
        400,
        337,
        11414,
        11,
        321,
        500,
        380,
        362,
        300,
        709,
        18356,
        570,
        309,
        311,
        257,
        588,
        955,
        3547,
        13,
        50562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 142,
      "seek": 61708,
      "start": 621.0400000000001,
      "end": 623.8000000000001,
      "text": " I think somewhere around 50 60k right now.",
      "tokens": [
        50562,
        286,
        519,
        4079,
        926,
        2625,
        4060,
        74,
        558,
        586,
        13,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 143,
      "seek": 61708,
      "start": 623.8000000000001,
      "end": 629.76,
      "text": " So we have like, I guess, a step of one or ten dollars maybe.",
      "tokens": [
        50700,
        407,
        321,
        362,
        411,
        11,
        286,
        2041,
        11,
        257,
        1823,
        295,
        472,
        420,
        2064,
        3808,
        1310,
        13,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 144,
      "seek": 61708,
      "start": 629.76,
      "end": 630.76,
      "text": " So we have two things.",
      "tokens": [
        50998,
        407,
        321,
        362,
        732,
        721,
        13,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 145,
      "seek": 61708,
      "start": 630.76,
      "end": 635.5600000000001,
      "text": " We have steps and we have precision as well based on the decimal that you can put in.",
      "tokens": [
        51048,
        492,
        362,
        4439,
        293,
        321,
        362,
        18356,
        382,
        731,
        2361,
        322,
        264,
        26601,
        300,
        291,
        393,
        829,
        294,
        13,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 146,
      "seek": 61708,
      "start": 635.5600000000001,
      "end": 636.5600000000001,
      "text": " Got it.",
      "tokens": [
        51288,
        5803,
        309,
        13,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 147,
      "seek": 61708,
      "start": 636.5600000000001,
      "end": 637.5600000000001,
      "text": " Sense.",
      "tokens": [
        51338,
        33123,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 148,
      "seek": 61708,
      "start": 637.5600000000001,
      "end": 644.12,
      "text": " So I heard that you've gone through a few, you know, through a few upgrades in the last",
      "tokens": [
        51388,
        407,
        286,
        2198,
        300,
        291,
        600,
        2780,
        807,
        257,
        1326,
        11,
        291,
        458,
        11,
        807,
        257,
        1326,
        24868,
        294,
        264,
        1036,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 149,
      "seek": 61708,
      "start": 644.12,
      "end": 645.12,
      "text": " few months.",
      "tokens": [
        51716,
        1326,
        2493,
        13,
        51766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22504067420959473,
      "compression_ratio": 1.6284584980237153,
      "no_speech_prob": 0.0010424411157146096
    },
    {
      "id": 150,
      "seek": 64512,
      "start": 645.2,
      "end": 648.2,
      "text": " You launched Treppa V1 and the last three months you moved to V2.",
      "tokens": [
        50368,
        509,
        8730,
        8648,
        34827,
        691,
        16,
        293,
        264,
        1036,
        1045,
        2493,
        291,
        4259,
        281,
        691,
        17,
        13,
        50518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 151,
      "seek": 64512,
      "start": 648.2,
      "end": 651.6,
      "text": " That's like a very big change to change things at the protocol level.",
      "tokens": [
        50518,
        663,
        311,
        411,
        257,
        588,
        955,
        1319,
        281,
        1319,
        721,
        412,
        264,
        10336,
        1496,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 152,
      "seek": 64512,
      "start": 651.6,
      "end": 655.92,
      "text": " So what do you think went wrong with version one that you had to start over and, you know,",
      "tokens": [
        50688,
        407,
        437,
        360,
        291,
        519,
        1437,
        2085,
        365,
        3037,
        472,
        300,
        291,
        632,
        281,
        722,
        670,
        293,
        11,
        291,
        458,
        11,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 153,
      "seek": 64512,
      "start": 655.92,
      "end": 660.92,
      "text": " create a new version to even before, you know, any traction?",
      "tokens": [
        50904,
        1884,
        257,
        777,
        3037,
        281,
        754,
        949,
        11,
        291,
        458,
        11,
        604,
        23558,
        30,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 154,
      "seek": 64512,
      "start": 660.92,
      "end": 667.0,
      "text": " So when I joined Treppa, we already had version one, which was live on DevNet and we had a",
      "tokens": [
        51154,
        407,
        562,
        286,
        6869,
        8648,
        34827,
        11,
        321,
        1217,
        632,
        3037,
        472,
        11,
        597,
        390,
        1621,
        322,
        9096,
        31890,
        293,
        321,
        632,
        257,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 155,
      "seek": 64512,
      "start": 667.0,
      "end": 668.84,
      "text": " lot of better testers.",
      "tokens": [
        51458,
        688,
        295,
        1101,
        1500,
        433,
        13,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 156,
      "seek": 64512,
      "start": 668.84,
      "end": 674.24,
      "text": " So version one was very good to validate the idea because before we kind of stuck into",
      "tokens": [
        51550,
        407,
        3037,
        472,
        390,
        588,
        665,
        281,
        29562,
        264,
        1558,
        570,
        949,
        321,
        733,
        295,
        5541,
        666,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2838982574699461,
      "compression_ratio": 1.7062937062937062,
      "no_speech_prob": 0.08213498443365097
    },
    {
      "id": 157,
      "seek": 67424,
      "start": 674.48,
      "end": 679.8,
      "text": " precision prediction, we like pivoted a lot and experimented a lot with different ideas",
      "tokens": [
        50376,
        18356,
        17630,
        11,
        321,
        411,
        14538,
        292,
        257,
        688,
        293,
        5120,
        292,
        257,
        688,
        365,
        819,
        3487,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 158,
      "seek": 67424,
      "start": 679.8,
      "end": 681.84,
      "text": " like social prediction and everything.",
      "tokens": [
        50642,
        411,
        2093,
        17630,
        293,
        1203,
        13,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 159,
      "seek": 67424,
      "start": 681.84,
      "end": 687.52,
      "text": " So V1 was built in stealth mode where you're shipping just to validate that if this works",
      "tokens": [
        50744,
        407,
        691,
        16,
        390,
        3094,
        294,
        25756,
        4391,
        689,
        291,
        434,
        14122,
        445,
        281,
        29562,
        300,
        498,
        341,
        1985,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 160,
      "seek": 67424,
      "start": 687.52,
      "end": 688.8,
      "text": " or not.",
      "tokens": [
        51028,
        420,
        406,
        13,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 161,
      "seek": 67424,
      "start": 688.8,
      "end": 693.48,
      "text": " And once we once I actually looked over the code, I realized there were a few things that",
      "tokens": [
        51092,
        400,
        1564,
        321,
        1564,
        286,
        767,
        2956,
        670,
        264,
        3089,
        11,
        286,
        5334,
        456,
        645,
        257,
        1326,
        721,
        300,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 162,
      "seek": 67424,
      "start": 693.48,
      "end": 694.84,
      "text": " could be improved.",
      "tokens": [
        51326,
        727,
        312,
        9689,
        13,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 163,
      "seek": 67424,
      "start": 694.84,
      "end": 696.32,
      "text": " And that's why it needed.",
      "tokens": [
        51394,
        400,
        300,
        311,
        983,
        309,
        2978,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 164,
      "seek": 67424,
      "start": 696.32,
      "end": 701.6800000000001,
      "text": " We needed to start it over instead of just iterating over the current version.",
      "tokens": [
        51468,
        492,
        2978,
        281,
        722,
        309,
        670,
        2602,
        295,
        445,
        17138,
        990,
        670,
        264,
        2190,
        3037,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18402953541606937,
      "compression_ratio": 1.6653992395437263,
      "no_speech_prob": 0.004746730905026197
    },
    {
      "id": 165,
      "seek": 70168,
      "start": 701.68,
      "end": 704.56,
      "text": " If you don't mind me getting more technical inside it.",
      "tokens": [
        50364,
        759,
        291,
        500,
        380,
        1575,
        385,
        1242,
        544,
        6191,
        1854,
        309,
        13,
        50508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 166,
      "seek": 70168,
      "start": 704.56,
      "end": 710.9599999999999,
      "text": " So basically, first thing I noticed is the account layout structure that we have.",
      "tokens": [
        50508,
        407,
        1936,
        11,
        700,
        551,
        286,
        5694,
        307,
        264,
        2696,
        13333,
        3877,
        300,
        321,
        362,
        13,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 167,
      "seek": 70168,
      "start": 710.9599999999999,
      "end": 712.3199999999999,
      "text": " We had an anchor program.",
      "tokens": [
        50828,
        492,
        632,
        364,
        18487,
        1461,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 168,
      "seek": 70168,
      "start": 712.3199999999999,
      "end": 717.1999999999999,
      "text": " So the structure that we have for like a PD account, it was very restrictive.",
      "tokens": [
        50896,
        407,
        264,
        3877,
        300,
        321,
        362,
        337,
        411,
        257,
        10464,
        2696,
        11,
        309,
        390,
        588,
        43220,
        13,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 169,
      "seek": 70168,
      "start": 717.1999999999999,
      "end": 719.3599999999999,
      "text": " You cannot put in more.",
      "tokens": [
        51140,
        509,
        2644,
        829,
        294,
        544,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 170,
      "seek": 70168,
      "start": 719.3599999999999,
      "end": 723.0799999999999,
      "text": " It didn't have any reserved bytes so that you can't expand the account structure in",
      "tokens": [
        51248,
        467,
        994,
        380,
        362,
        604,
        24819,
        36088,
        370,
        300,
        291,
        393,
        380,
        5268,
        264,
        2696,
        3877,
        294,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 171,
      "seek": 70168,
      "start": 723.0799999999999,
      "end": 724.0799999999999,
      "text": " future.",
      "tokens": [
        51434,
        2027,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 172,
      "seek": 70168,
      "start": 724.0799999999999,
      "end": 726.76,
      "text": " And I know you can just create a new contract.",
      "tokens": [
        51484,
        400,
        286,
        458,
        291,
        393,
        445,
        1884,
        257,
        777,
        4364,
        13,
        51618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17974646432059152,
      "compression_ratio": 1.665289256198347,
      "no_speech_prob": 0.029854560270905495
    },
    {
      "id": 173,
      "seek": 72676,
      "start": 726.76,
      "end": 732.16,
      "text": " But for let's say small feature updates, because we added a step feature, I guess, a month",
      "tokens": [
        50364,
        583,
        337,
        718,
        311,
        584,
        1359,
        4111,
        9205,
        11,
        570,
        321,
        3869,
        257,
        1823,
        4111,
        11,
        286,
        2041,
        11,
        257,
        1618,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 174,
      "seek": 72676,
      "start": 732.16,
      "end": 734.4399999999999,
      "text": " back, even after we launched.",
      "tokens": [
        50634,
        646,
        11,
        754,
        934,
        321,
        8730,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 175,
      "seek": 72676,
      "start": 734.4399999999999,
      "end": 739.84,
      "text": " So that is something that we were able to incorporate without creating a new contract",
      "tokens": [
        50748,
        407,
        300,
        307,
        746,
        300,
        321,
        645,
        1075,
        281,
        16091,
        1553,
        4084,
        257,
        777,
        4364,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 176,
      "seek": 72676,
      "start": 739.84,
      "end": 741.76,
      "text": " is we could increase the account.",
      "tokens": [
        51018,
        307,
        321,
        727,
        3488,
        264,
        2696,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 177,
      "seek": 72676,
      "start": 741.76,
      "end": 744.6,
      "text": " We could add new variables in the account structure.",
      "tokens": [
        51114,
        492,
        727,
        909,
        777,
        9102,
        294,
        264,
        2696,
        3877,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 178,
      "seek": 72676,
      "start": 744.6,
      "end": 745.6,
      "text": " Right.",
      "tokens": [
        51256,
        1779,
        13,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 179,
      "seek": 72676,
      "start": 745.6,
      "end": 748.28,
      "text": " So that's the first thing that I wanted to change.",
      "tokens": [
        51306,
        407,
        300,
        311,
        264,
        700,
        551,
        300,
        286,
        1415,
        281,
        1319,
        13,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 180,
      "seek": 72676,
      "start": 748.28,
      "end": 753.8,
      "text": " And second thing was related to scaling as it's a consumer platform where users would",
      "tokens": [
        51440,
        400,
        1150,
        551,
        390,
        4077,
        281,
        21589,
        382,
        309,
        311,
        257,
        9711,
        3663,
        689,
        5022,
        576,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20950096624868889,
      "compression_ratio": 1.6743295019157087,
      "no_speech_prob": 0.25011080503463745
    },
    {
      "id": 181,
      "seek": 75380,
      "start": 753.88,
      "end": 758.7199999999999,
      "text": " be clicking a lot of buttons, making a lot of transaction, let's say for predicting,",
      "tokens": [
        50368,
        312,
        9697,
        257,
        688,
        295,
        9905,
        11,
        1455,
        257,
        688,
        295,
        14425,
        11,
        718,
        311,
        584,
        337,
        32884,
        11,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 182,
      "seek": 75380,
      "start": 758.7199999999999,
      "end": 761.4,
      "text": " updating the stake, claiming the rewards.",
      "tokens": [
        50610,
        25113,
        264,
        10407,
        11,
        19232,
        264,
        17203,
        13,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 183,
      "seek": 75380,
      "start": 761.4,
      "end": 764.78,
      "text": " It also means that data is getting stored on chain.",
      "tokens": [
        50744,
        467,
        611,
        1355,
        300,
        1412,
        307,
        1242,
        12187,
        322,
        5021,
        13,
        50913
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 184,
      "seek": 75380,
      "start": 764.78,
      "end": 767.0799999999999,
      "text": " So we need to be mindful of what we store.",
      "tokens": [
        50913,
        407,
        321,
        643,
        281,
        312,
        14618,
        295,
        437,
        321,
        3531,
        13,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 185,
      "seek": 75380,
      "start": 767.0799999999999,
      "end": 771.8399999999999,
      "text": " I know when we write a contract, we tend to write, put everything on chain, like let's",
      "tokens": [
        51028,
        286,
        458,
        562,
        321,
        2464,
        257,
        4364,
        11,
        321,
        3928,
        281,
        2464,
        11,
        829,
        1203,
        322,
        5021,
        11,
        411,
        718,
        311,
        51266
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 186,
      "seek": 75380,
      "start": 771.8399999999999,
      "end": 774.7199999999999,
      "text": " put everything related to the user.",
      "tokens": [
        51266,
        829,
        1203,
        4077,
        281,
        264,
        4195,
        13,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 187,
      "seek": 75380,
      "start": 774.7199999999999,
      "end": 779.8399999999999,
      "text": " But at some point, you may need to draw a line of what you actually end up storing on",
      "tokens": [
        51410,
        583,
        412,
        512,
        935,
        11,
        291,
        815,
        643,
        281,
        2642,
        257,
        1622,
        295,
        437,
        291,
        767,
        917,
        493,
        26085,
        322,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18944718352461284,
      "compression_ratio": 1.7408906882591093,
      "no_speech_prob": 0.2616077959537506
    },
    {
      "id": 188,
      "seek": 77984,
      "start": 779.9200000000001,
      "end": 784.6800000000001,
      "text": " chain, what will help in your logic and what is like redundant data.",
      "tokens": [
        50368,
        5021,
        11,
        437,
        486,
        854,
        294,
        428,
        9952,
        293,
        437,
        307,
        411,
        40997,
        1412,
        13,
        50606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 189,
      "seek": 77984,
      "start": 784.6800000000001,
      "end": 785.6800000000001,
      "text": " Right.",
      "tokens": [
        50606,
        1779,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 190,
      "seek": 77984,
      "start": 785.6800000000001,
      "end": 791.32,
      "text": " So these were the two things that I wanted to make sure that we think through and we",
      "tokens": [
        50656,
        407,
        613,
        645,
        264,
        732,
        721,
        300,
        286,
        1415,
        281,
        652,
        988,
        300,
        321,
        519,
        807,
        293,
        321,
        50938
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 191,
      "seek": 77984,
      "start": 791.32,
      "end": 792.44,
      "text": " take in the cost.",
      "tokens": [
        50938,
        747,
        294,
        264,
        2063,
        13,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 192,
      "seek": 77984,
      "start": 792.44,
      "end": 796.86,
      "text": " So I actually sat down and at that time, I guess, sold was $200.",
      "tokens": [
        50994,
        407,
        286,
        767,
        3227,
        760,
        293,
        412,
        300,
        565,
        11,
        286,
        2041,
        11,
        3718,
        390,
        1848,
        7629,
        13,
        51215
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 193,
      "seek": 77984,
      "start": 796.86,
      "end": 803.2800000000001,
      "text": " So I did some calculations based on how much it will cost to store user prediction.",
      "tokens": [
        51215,
        407,
        286,
        630,
        512,
        20448,
        2361,
        322,
        577,
        709,
        309,
        486,
        2063,
        281,
        3531,
        4195,
        17630,
        13,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 194,
      "seek": 77984,
      "start": 803.2800000000001,
      "end": 807.98,
      "text": " And we also ended up adding a new instruction to close prediction accounts.",
      "tokens": [
        51536,
        400,
        321,
        611,
        4590,
        493,
        5127,
        257,
        777,
        10951,
        281,
        1998,
        17630,
        9402,
        13,
        51771
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19428545633951824,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.26144272089004517
    },
    {
      "id": 195,
      "seek": 80798,
      "start": 807.98,
      "end": 812.4200000000001,
      "text": " So after the pool is over, after some time, we close the accounts as not needed and then",
      "tokens": [
        50364,
        407,
        934,
        264,
        7005,
        307,
        670,
        11,
        934,
        512,
        565,
        11,
        321,
        1998,
        264,
        9402,
        382,
        406,
        2978,
        293,
        550,
        50586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 196,
      "seek": 80798,
      "start": 812.4200000000001,
      "end": 814.28,
      "text": " claim the fees back.",
      "tokens": [
        50586,
        3932,
        264,
        13370,
        646,
        13,
        50679
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 197,
      "seek": 80798,
      "start": 814.28,
      "end": 816.1800000000001,
      "text": " If we are sponsoring, we claim it for ourselves.",
      "tokens": [
        50679,
        759,
        321,
        366,
        30311,
        11,
        321,
        3932,
        309,
        337,
        4175,
        13,
        50774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 198,
      "seek": 80798,
      "start": 816.1800000000001,
      "end": 819.5,
      "text": " If the user is sponsoring, they get it back automatically.",
      "tokens": [
        50774,
        759,
        264,
        4195,
        307,
        30311,
        11,
        436,
        483,
        309,
        646,
        6772,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 199,
      "seek": 80798,
      "start": 819.5,
      "end": 824.4200000000001,
      "text": " So you're saying changes are made more around optimizing the existing contract and not in",
      "tokens": [
        50940,
        407,
        291,
        434,
        1566,
        2962,
        366,
        1027,
        544,
        926,
        40425,
        264,
        6741,
        4364,
        293,
        406,
        294,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 200,
      "seek": 80798,
      "start": 824.4200000000001,
      "end": 829.38,
      "text": " terms of how the contract works or the math.",
      "tokens": [
        51186,
        2115,
        295,
        577,
        264,
        4364,
        1985,
        420,
        264,
        5221,
        13,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 201,
      "seek": 80798,
      "start": 829.38,
      "end": 833.38,
      "text": " Have you gone through security audit and what was the process like specifically because",
      "tokens": [
        51434,
        3560,
        291,
        2780,
        807,
        3825,
        17748,
        293,
        437,
        390,
        264,
        1399,
        411,
        4682,
        570,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 202,
      "seek": 80798,
      "start": 833.38,
      "end": 836.22,
      "text": " this is a new sort of a primitive that you created?",
      "tokens": [
        51634,
        341,
        307,
        257,
        777,
        1333,
        295,
        257,
        28540,
        300,
        291,
        2942,
        30,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2617080817788334,
      "compression_ratio": 1.690721649484536,
      "no_speech_prob": 0.04591123387217522
    },
    {
      "id": 203,
      "seek": 83622,
      "start": 836.22,
      "end": 840.82,
      "text": " Was it hard for the auditors to be able to understand the project or other new set of",
      "tokens": [
        50364,
        3027,
        309,
        1152,
        337,
        264,
        2379,
        9862,
        281,
        312,
        1075,
        281,
        1223,
        264,
        1716,
        420,
        661,
        777,
        992,
        295,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23475860146915212,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.025685757398605347
    },
    {
      "id": 204,
      "seek": 83622,
      "start": 840.82,
      "end": 845.34,
      "text": " attack vectors when it comes to a new primitive like this?",
      "tokens": [
        50594,
        2690,
        18875,
        562,
        309,
        1487,
        281,
        257,
        777,
        28540,
        411,
        341,
        30,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23475860146915212,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.025685757398605347
    },
    {
      "id": 205,
      "seek": 83622,
      "start": 845.34,
      "end": 851.58,
      "text": " So before our launch, we went through an audit with AdWare Labs and we got a contract as",
      "tokens": [
        50820,
        407,
        949,
        527,
        4025,
        11,
        321,
        1437,
        807,
        364,
        17748,
        365,
        1999,
        54,
        543,
        40047,
        293,
        321,
        658,
        257,
        4364,
        382,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23475860146915212,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.025685757398605347
    },
    {
      "id": 206,
      "seek": 83622,
      "start": 851.58,
      "end": 856.98,
      "text": " well as a utility library, which basically caused a contract audited.",
      "tokens": [
        51132,
        731,
        382,
        257,
        14877,
        6405,
        11,
        597,
        1936,
        7008,
        257,
        4364,
        2379,
        1226,
        13,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23475860146915212,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.025685757398605347
    },
    {
      "id": 207,
      "seek": 83622,
      "start": 856.98,
      "end": 859.34,
      "text": " And it was a very amazing experience.",
      "tokens": [
        51402,
        400,
        309,
        390,
        257,
        588,
        2243,
        1752,
        13,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23475860146915212,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.025685757398605347
    },
    {
      "id": 208,
      "seek": 83622,
      "start": 859.34,
      "end": 863.34,
      "text": " The team is really great at AdWare Labs with prediction market.",
      "tokens": [
        51520,
        440,
        1469,
        307,
        534,
        869,
        412,
        1999,
        54,
        543,
        40047,
        365,
        17630,
        2142,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23475860146915212,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.025685757398605347
    },
    {
      "id": 209,
      "seek": 86334,
      "start": 863.34,
      "end": 868.62,
      "text": " We had an onboarding call and because it's very different from what Polymarket or Kalshi",
      "tokens": [
        50364,
        492,
        632,
        364,
        24033,
        278,
        818,
        293,
        570,
        309,
        311,
        588,
        819,
        490,
        437,
        18553,
        16414,
        420,
        591,
        1124,
        4954,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3112565242882931,
      "compression_ratio": 1.6065573770491803,
      "no_speech_prob": 0.15934664011001587
    },
    {
      "id": 210,
      "seek": 86334,
      "start": 868.62,
      "end": 875.82,
      "text": " is, it's basically running on math and you have a very different set of logic where money",
      "tokens": [
        50628,
        307,
        11,
        309,
        311,
        1936,
        2614,
        322,
        5221,
        293,
        291,
        362,
        257,
        588,
        819,
        992,
        295,
        9952,
        689,
        1460,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3112565242882931,
      "compression_ratio": 1.6065573770491803,
      "no_speech_prob": 0.15934664011001587
    },
    {
      "id": 211,
      "seek": 86334,
      "start": 875.82,
      "end": 878.62,
      "text": " is going inside a single pool and it's coming out from that.",
      "tokens": [
        50988,
        307,
        516,
        1854,
        257,
        2167,
        7005,
        293,
        309,
        311,
        1348,
        484,
        490,
        300,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3112565242882931,
      "compression_ratio": 1.6065573770491803,
      "no_speech_prob": 0.15934664011001587
    },
    {
      "id": 212,
      "seek": 86334,
      "start": 878.62,
      "end": 882.7,
      "text": " It's not you're not creating tokens or trading with those tokens.",
      "tokens": [
        51128,
        467,
        311,
        406,
        291,
        434,
        406,
        4084,
        22667,
        420,
        9529,
        365,
        729,
        22667,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3112565242882931,
      "compression_ratio": 1.6065573770491803,
      "no_speech_prob": 0.15934664011001587
    },
    {
      "id": 213,
      "seek": 86334,
      "start": 882.7,
      "end": 889.5,
      "text": " So I feel like the auditors at AdWare Labs are really good at understanding what we're",
      "tokens": [
        51332,
        407,
        286,
        841,
        411,
        264,
        2379,
        9862,
        412,
        1999,
        54,
        543,
        40047,
        366,
        534,
        665,
        412,
        3701,
        437,
        321,
        434,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3112565242882931,
      "compression_ratio": 1.6065573770491803,
      "no_speech_prob": 0.15934664011001587
    },
    {
      "id": 214,
      "seek": 88950,
      "start": 889.5,
      "end": 894.22,
      "text": " building and they did a great job with our audit itself.",
      "tokens": [
        50364,
        2390,
        293,
        436,
        630,
        257,
        869,
        1691,
        365,
        527,
        17748,
        2564,
        13,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1550349322232333,
      "compression_ratio": 1.511737089201878,
      "no_speech_prob": 0.44095006585121155
    },
    {
      "id": 215,
      "seek": 88950,
      "start": 896.38,
      "end": 899.98,
      "text": " We didn't find any critical issue with the contract at all.",
      "tokens": [
        50708,
        492,
        994,
        380,
        915,
        604,
        4924,
        2734,
        365,
        264,
        4364,
        412,
        439,
        13,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1550349322232333,
      "compression_ratio": 1.511737089201878,
      "no_speech_prob": 0.44095006585121155
    },
    {
      "id": 216,
      "seek": 88950,
      "start": 899.98,
      "end": 902.46,
      "text": " I know it's a kind of like a self compliment.",
      "tokens": [
        50888,
        286,
        458,
        309,
        311,
        257,
        733,
        295,
        411,
        257,
        2698,
        16250,
        13,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1550349322232333,
      "compression_ratio": 1.511737089201878,
      "no_speech_prob": 0.44095006585121155
    },
    {
      "id": 217,
      "seek": 88950,
      "start": 903.9,
      "end": 909.82,
      "text": " The only important one, which I didn't know personally and I got to know after the audit",
      "tokens": [
        51084,
        440,
        787,
        1021,
        472,
        11,
        597,
        286,
        994,
        380,
        458,
        5665,
        293,
        286,
        658,
        281,
        458,
        934,
        264,
        17748,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1550349322232333,
      "compression_ratio": 1.511737089201878,
      "no_speech_prob": 0.44095006585121155
    },
    {
      "id": 218,
      "seek": 88950,
      "start": 909.82,
      "end": 912.94,
      "text": " was emitting CPI.",
      "tokens": [
        51380,
        390,
        846,
        2414,
        22431,
        40,
        13,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1550349322232333,
      "compression_ratio": 1.511737089201878,
      "no_speech_prob": 0.44095006585121155
    },
    {
      "id": 219,
      "seek": 88950,
      "start": 912.94,
      "end": 917.5,
      "text": " So basically on Solana, you could emit program logs.",
      "tokens": [
        51536,
        407,
        1936,
        322,
        7026,
        2095,
        11,
        291,
        727,
        32084,
        1461,
        20820,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1550349322232333,
      "compression_ratio": 1.511737089201878,
      "no_speech_prob": 0.44095006585121155
    },
    {
      "id": 220,
      "seek": 91750,
      "start": 917.5,
      "end": 923.58,
      "text": " And I was actually relying on them to get the prediction a user made because to me,",
      "tokens": [
        50364,
        400,
        286,
        390,
        767,
        24140,
        322,
        552,
        281,
        483,
        264,
        17630,
        257,
        4195,
        1027,
        570,
        281,
        385,
        11,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800680025659425,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.00047878161421976984
    },
    {
      "id": 221,
      "seek": 91750,
      "start": 923.58,
      "end": 925.9,
      "text": " it didn't make sense to put it on chain.",
      "tokens": [
        50668,
        309,
        994,
        380,
        652,
        2020,
        281,
        829,
        309,
        322,
        5021,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800680025659425,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.00047878161421976984
    },
    {
      "id": 222,
      "seek": 91750,
      "start": 925.9,
      "end": 931.98,
      "text": " We only put stake amount on chain in a PDA and we were emitting the data, the prediction",
      "tokens": [
        50784,
        492,
        787,
        829,
        10407,
        2372,
        322,
        5021,
        294,
        257,
        430,
        7509,
        293,
        321,
        645,
        846,
        2414,
        264,
        1412,
        11,
        264,
        17630,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800680025659425,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.00047878161421976984
    },
    {
      "id": 223,
      "seek": 91750,
      "start": 931.98,
      "end": 935.66,
      "text": " that a user was making via program logs.",
      "tokens": [
        51088,
        300,
        257,
        4195,
        390,
        1455,
        5766,
        1461,
        20820,
        13,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800680025659425,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.00047878161421976984
    },
    {
      "id": 224,
      "seek": 91750,
      "start": 935.66,
      "end": 941.98,
      "text": " And we had an indexer which will scoop up everything and store it in our database so",
      "tokens": [
        51272,
        400,
        321,
        632,
        364,
        8186,
        260,
        597,
        486,
        19555,
        493,
        1203,
        293,
        3531,
        309,
        294,
        527,
        8149,
        370,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800680025659425,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.00047878161421976984
    },
    {
      "id": 225,
      "seek": 91750,
      "start": 941.98,
      "end": 943.98,
      "text": " that it reflects on our UI itself.",
      "tokens": [
        51588,
        300,
        309,
        18926,
        322,
        527,
        15682,
        2564,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800680025659425,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.00047878161421976984
    },
    {
      "id": 226,
      "seek": 94398,
      "start": 944.62,
      "end": 950.62,
      "text": " One thing I didn't realize that RPC providers, they can actually truncate your program logs.",
      "tokens": [
        50396,
        1485,
        551,
        286,
        994,
        380,
        4325,
        300,
        497,
        12986,
        11330,
        11,
        436,
        393,
        767,
        504,
        409,
        66,
        473,
        428,
        1461,
        20820,
        13,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 227,
      "seek": 94398,
      "start": 950.62,
      "end": 953.34,
      "text": " I guess somewhere around 12 KB they allow.",
      "tokens": [
        50696,
        286,
        2041,
        4079,
        926,
        2272,
        591,
        33,
        436,
        2089,
        13,
        50832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 228,
      "seek": 94398,
      "start": 953.34,
      "end": 954.78,
      "text": " And that could be an issue.",
      "tokens": [
        50832,
        400,
        300,
        727,
        312,
        364,
        2734,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 229,
      "seek": 94398,
      "start": 954.78,
      "end": 958.86,
      "text": " We could end up missing some predictions that users made.",
      "tokens": [
        50904,
        492,
        727,
        917,
        493,
        5361,
        512,
        21264,
        300,
        5022,
        1027,
        13,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 230,
      "seek": 94398,
      "start": 958.86,
      "end": 959.58,
      "text": " Right.",
      "tokens": [
        51108,
        1779,
        13,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 231,
      "seek": 94398,
      "start": 959.58,
      "end": 966.22,
      "text": " So the alternative to that is just using an emit CPI macro instead of an emit macro.",
      "tokens": [
        51144,
        407,
        264,
        8535,
        281,
        300,
        307,
        445,
        1228,
        364,
        32084,
        22431,
        40,
        18887,
        2602,
        295,
        364,
        32084,
        18887,
        13,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 232,
      "seek": 94398,
      "start": 967.74,
      "end": 970.46,
      "text": " It's a very no op stuff that you add.",
      "tokens": [
        51552,
        467,
        311,
        257,
        588,
        572,
        999,
        1507,
        300,
        291,
        909,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15013563389680823,
      "compression_ratio": 1.5064377682403434,
      "no_speech_prob": 0.0020383645314723253
    },
    {
      "id": 233,
      "seek": 97046,
      "start": 970.46,
      "end": 975.34,
      "text": " What it does, it calls the same instruction again with the instruction data as the log",
      "tokens": [
        50364,
        708,
        309,
        775,
        11,
        309,
        5498,
        264,
        912,
        10951,
        797,
        365,
        264,
        10951,
        1412,
        382,
        264,
        3565,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 234,
      "seek": 97046,
      "start": 975.34,
      "end": 976.62,
      "text": " that you wanted to pass.",
      "tokens": [
        50608,
        300,
        291,
        1415,
        281,
        1320,
        13,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 235,
      "seek": 97046,
      "start": 976.62,
      "end": 978.62,
      "text": " You pass it as an instruction data.",
      "tokens": [
        50672,
        509,
        1320,
        309,
        382,
        364,
        10951,
        1412,
        13,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 236,
      "seek": 97046,
      "start": 978.62,
      "end": 979.26,
      "text": " So it's there.",
      "tokens": [
        50772,
        407,
        309,
        311,
        456,
        13,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 237,
      "seek": 97046,
      "start": 979.26,
      "end": 985.6600000000001,
      "text": " You can always fetch the transaction and get all the data that you want directly instead",
      "tokens": [
        50804,
        509,
        393,
        1009,
        23673,
        264,
        14425,
        293,
        483,
        439,
        264,
        1412,
        300,
        291,
        528,
        3838,
        2602,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 238,
      "seek": 97046,
      "start": 985.6600000000001,
      "end": 987.1800000000001,
      "text": " of relying on the logs.",
      "tokens": [
        51124,
        295,
        24140,
        322,
        264,
        20820,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 239,
      "seek": 97046,
      "start": 987.1800000000001,
      "end": 992.86,
      "text": " So that is something which was quite eye opening that I saw that I noticed that this could",
      "tokens": [
        51200,
        407,
        300,
        307,
        746,
        597,
        390,
        1596,
        3313,
        5193,
        300,
        286,
        1866,
        300,
        286,
        5694,
        300,
        341,
        727,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 240,
      "seek": 97046,
      "start": 992.86,
      "end": 993.4200000000001,
      "text": " be an issue.",
      "tokens": [
        51484,
        312,
        364,
        2734,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 241,
      "seek": 97046,
      "start": 993.4200000000001,
      "end": 994.7800000000001,
      "text": " All right.",
      "tokens": [
        51512,
        1057,
        558,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 242,
      "seek": 97046,
      "start": 994.7800000000001,
      "end": 995.34,
      "text": " Very interesting.",
      "tokens": [
        51580,
        4372,
        1880,
        13,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1594095583315249,
      "compression_ratio": 1.7586206896551724,
      "no_speech_prob": 0.07149200886487961
    },
    {
      "id": 243,
      "seek": 99534,
      "start": 995.34,
      "end": 1001.02,
      "text": " You mentioned a very intriguing architecture right now, which is you decide what to store",
      "tokens": [
        50364,
        509,
        2835,
        257,
        588,
        32503,
        9482,
        558,
        586,
        11,
        597,
        307,
        291,
        4536,
        437,
        281,
        3531,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 244,
      "seek": 99534,
      "start": 1001.02,
      "end": 1002.46,
      "text": " on chain and what not to store on chain.",
      "tokens": [
        50648,
        322,
        5021,
        293,
        437,
        406,
        281,
        3531,
        322,
        5021,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 245,
      "seek": 99534,
      "start": 1002.46,
      "end": 1007.1800000000001,
      "text": " And there are things that are logged in the program or in an instruction that you actually",
      "tokens": [
        50720,
        400,
        456,
        366,
        721,
        300,
        366,
        27231,
        294,
        264,
        1461,
        420,
        294,
        364,
        10951,
        300,
        291,
        767,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 246,
      "seek": 99534,
      "start": 1007.1800000000001,
      "end": 1007.74,
      "text": " scoop up through.",
      "tokens": [
        50956,
        19555,
        493,
        807,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 247,
      "seek": 99534,
      "start": 1009.1,
      "end": 1014.7,
      "text": " Can you talk to maybe specifically as to a few examples of maybe not in Trepa, maybe",
      "tokens": [
        51052,
        1664,
        291,
        751,
        281,
        1310,
        4682,
        382,
        281,
        257,
        1326,
        5110,
        295,
        1310,
        406,
        294,
        8648,
        4306,
        11,
        1310,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 248,
      "seek": 99534,
      "start": 1014.7,
      "end": 1017.1800000000001,
      "text": " in Trepa where this architecture sort of depends?",
      "tokens": [
        51332,
        294,
        8648,
        4306,
        689,
        341,
        9482,
        1333,
        295,
        5946,
        30,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 249,
      "seek": 99534,
      "start": 1017.98,
      "end": 1021.82,
      "text": " Because mostly from what I can tell or most places I've seen, you just store everything",
      "tokens": [
        51496,
        1436,
        5240,
        490,
        437,
        286,
        393,
        980,
        420,
        881,
        3190,
        286,
        600,
        1612,
        11,
        291,
        445,
        3531,
        1203,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211655703457919,
      "compression_ratio": 1.6985294117647058,
      "no_speech_prob": 0.04101160913705826
    },
    {
      "id": 250,
      "seek": 102182,
      "start": 1021.82,
      "end": 1027.74,
      "text": " on chain and you want to avoid the complexity and you sort of are for more companies at",
      "tokens": [
        50364,
        322,
        5021,
        293,
        291,
        528,
        281,
        5042,
        264,
        14024,
        293,
        291,
        1333,
        295,
        366,
        337,
        544,
        3431,
        412,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 251,
      "seek": 102182,
      "start": 1027.74,
      "end": 1030.94,
      "text": " least you're offloading the rent to the end user.",
      "tokens": [
        50660,
        1935,
        291,
        434,
        766,
        2907,
        278,
        264,
        6214,
        281,
        264,
        917,
        4195,
        13,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 252,
      "seek": 102182,
      "start": 1030.94,
      "end": 1032.38,
      "text": " So it doesn't matter if you're storing more.",
      "tokens": [
        50820,
        407,
        309,
        1177,
        380,
        1871,
        498,
        291,
        434,
        26085,
        544,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 253,
      "seek": 102182,
      "start": 1033.02,
      "end": 1037.8200000000002,
      "text": " I think in your case, Trepa sponsors the gas if I'm not wrong.",
      "tokens": [
        50924,
        286,
        519,
        294,
        428,
        1389,
        11,
        8648,
        4306,
        22593,
        264,
        4211,
        498,
        286,
        478,
        406,
        2085,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 254,
      "seek": 102182,
      "start": 1037.8200000000002,
      "end": 1043.18,
      "text": " But I'd love to know one specific use case, this architecture specifically makes sense.",
      "tokens": [
        51164,
        583,
        286,
        1116,
        959,
        281,
        458,
        472,
        2685,
        764,
        1389,
        11,
        341,
        9482,
        4682,
        1669,
        2020,
        13,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 255,
      "seek": 102182,
      "start": 1043.18,
      "end": 1044.22,
      "text": " You said the prediction, right?",
      "tokens": [
        51432,
        509,
        848,
        264,
        17630,
        11,
        558,
        30,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 256,
      "seek": 102182,
      "start": 1044.22,
      "end": 1046.38,
      "text": " You mentioned a yes, not a yes or no.",
      "tokens": [
        51484,
        509,
        2835,
        257,
        2086,
        11,
        406,
        257,
        2086,
        420,
        572,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 257,
      "seek": 102182,
      "start": 1046.38,
      "end": 1046.6200000000001,
      "text": " Sorry.",
      "tokens": [
        51592,
        4919,
        13,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 258,
      "seek": 102182,
      "start": 1046.6200000000001,
      "end": 1050.8600000000001,
      "text": " In your case, like a number that is so that prediction is never stored on chain in a",
      "tokens": [
        51604,
        682,
        428,
        1389,
        11,
        411,
        257,
        1230,
        300,
        307,
        370,
        300,
        17630,
        307,
        1128,
        12187,
        322,
        5021,
        294,
        257,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19001100328233506,
      "compression_ratio": 1.7247386759581882,
      "no_speech_prob": 0.08254953473806381
    },
    {
      "id": 259,
      "seek": 105086,
      "start": 1050.86,
      "end": 1051.4199999999998,
      "text": " structure.",
      "tokens": [
        50364,
        3877,
        13,
        50392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 260,
      "seek": 105086,
      "start": 1051.4199999999998,
      "end": 1053.4199999999998,
      "text": " It is just logged in a program.",
      "tokens": [
        50392,
        467,
        307,
        445,
        27231,
        294,
        257,
        1461,
        13,
        50492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 261,
      "seek": 105086,
      "start": 1053.4199999999998,
      "end": 1053.9799999999998,
      "text": " Is that correct?",
      "tokens": [
        50492,
        1119,
        300,
        3006,
        30,
        50520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 262,
      "seek": 105086,
      "start": 1055.5,
      "end": 1055.8999999999999,
      "text": " Yeah.",
      "tokens": [
        50596,
        865,
        13,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 263,
      "seek": 105086,
      "start": 1055.8999999999999,
      "end": 1058.2199999999998,
      "text": " So, okay.",
      "tokens": [
        50616,
        407,
        11,
        1392,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 264,
      "seek": 105086,
      "start": 1058.2199999999998,
      "end": 1059.58,
      "text": " There's a lot of questions here.",
      "tokens": [
        50732,
        821,
        311,
        257,
        688,
        295,
        1651,
        510,
        13,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 265,
      "seek": 105086,
      "start": 1059.58,
      "end": 1061.8999999999999,
      "text": " I'll just start with what I had in my mind.",
      "tokens": [
        50800,
        286,
        603,
        445,
        722,
        365,
        437,
        286,
        632,
        294,
        452,
        1575,
        13,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 266,
      "seek": 105086,
      "start": 1061.8999999999999,
      "end": 1067.74,
      "text": " So what we wanted to do that from the start, we had the idea that we would sponsor the gas",
      "tokens": [
        50916,
        407,
        437,
        321,
        1415,
        281,
        360,
        300,
        490,
        264,
        722,
        11,
        321,
        632,
        264,
        1558,
        300,
        321,
        576,
        16198,
        264,
        4211,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 267,
      "seek": 105086,
      "start": 1067.74,
      "end": 1071.02,
      "text": " fees given the predictions are made in USTC.",
      "tokens": [
        51208,
        13370,
        2212,
        264,
        21264,
        366,
        1027,
        294,
        2546,
        18238,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 268,
      "seek": 105086,
      "start": 1071.02,
      "end": 1075.9799999999998,
      "text": " We weren't want a user to come in and put two types of tokens like soul and USTC because",
      "tokens": [
        51372,
        492,
        4999,
        380,
        528,
        257,
        4195,
        281,
        808,
        294,
        293,
        829,
        732,
        3467,
        295,
        22667,
        411,
        5133,
        293,
        2546,
        18238,
        570,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 269,
      "seek": 105086,
      "start": 1075.9799999999998,
      "end": 1078.9399999999998,
      "text": " it's very confusing for the user.",
      "tokens": [
        51620,
        309,
        311,
        588,
        13181,
        337,
        264,
        4195,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18215085614112117,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.003307842882350087
    },
    {
      "id": 270,
      "seek": 107894,
      "start": 1078.94,
      "end": 1085.66,
      "text": " So we decided that we'll sponsor the fees, but sponsoring fees is a very different issue",
      "tokens": [
        50364,
        407,
        321,
        3047,
        300,
        321,
        603,
        16198,
        264,
        13370,
        11,
        457,
        30311,
        13370,
        307,
        257,
        588,
        819,
        2734,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1257538008458406,
      "compression_ratio": 1.6600790513833992,
      "no_speech_prob": 0.00038416005554609
    },
    {
      "id": 271,
      "seek": 107894,
      "start": 1085.66,
      "end": 1089.5800000000002,
      "text": " where you need to make sure that the cost is optimized for yourself as well.",
      "tokens": [
        50700,
        689,
        291,
        643,
        281,
        652,
        988,
        300,
        264,
        2063,
        307,
        26941,
        337,
        1803,
        382,
        731,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1257538008458406,
      "compression_ratio": 1.6600790513833992,
      "no_speech_prob": 0.00038416005554609
    },
    {
      "id": 272,
      "seek": 107894,
      "start": 1090.22,
      "end": 1092.46,
      "text": " You don't end up paying for a lot.",
      "tokens": [
        50928,
        509,
        500,
        380,
        917,
        493,
        6229,
        337,
        257,
        688,
        13,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1257538008458406,
      "compression_ratio": 1.6600790513833992,
      "no_speech_prob": 0.00038416005554609
    },
    {
      "id": 273,
      "seek": 107894,
      "start": 1093.02,
      "end": 1098.22,
      "text": " So that's why we needed I needed to be very deliberate with how the account structure",
      "tokens": [
        51068,
        407,
        300,
        311,
        983,
        321,
        2978,
        286,
        2978,
        281,
        312,
        588,
        30515,
        365,
        577,
        264,
        2696,
        3877,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1257538008458406,
      "compression_ratio": 1.6600790513833992,
      "no_speech_prob": 0.00038416005554609
    },
    {
      "id": 274,
      "seek": 107894,
      "start": 1098.22,
      "end": 1100.94,
      "text": " is so that we only store what matters.",
      "tokens": [
        51328,
        307,
        370,
        300,
        321,
        787,
        3531,
        437,
        7001,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1257538008458406,
      "compression_ratio": 1.6600790513833992,
      "no_speech_prob": 0.00038416005554609
    },
    {
      "id": 275,
      "seek": 107894,
      "start": 1101.5,
      "end": 1108.3,
      "text": " Now, I would have personally stored the stake amount of like a lot of chain in the instruction",
      "tokens": [
        51492,
        823,
        11,
        286,
        576,
        362,
        5665,
        12187,
        264,
        10407,
        2372,
        295,
        411,
        257,
        688,
        295,
        5021,
        294,
        264,
        10951,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1257538008458406,
      "compression_ratio": 1.6600790513833992,
      "no_speech_prob": 0.00038416005554609
    },
    {
      "id": 276,
      "seek": 110830,
      "start": 1108.3,
      "end": 1108.7,
      "text": " as well.",
      "tokens": [
        50364,
        382,
        731,
        13,
        50384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 277,
      "seek": 110830,
      "start": 1108.7,
      "end": 1114.3,
      "text": " The only reason I stored it on on chain in a PDA account is because we also have a feature",
      "tokens": [
        50384,
        440,
        787,
        1778,
        286,
        12187,
        309,
        322,
        322,
        5021,
        294,
        257,
        430,
        7509,
        2696,
        307,
        570,
        321,
        611,
        362,
        257,
        4111,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 278,
      "seek": 110830,
      "start": 1114.3,
      "end": 1115.82,
      "text": " of updating a stake value.",
      "tokens": [
        50664,
        295,
        25113,
        257,
        10407,
        2158,
        13,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 279,
      "seek": 110830,
      "start": 1116.3799999999999,
      "end": 1121.74,
      "text": " So that that's why if you want to update your stake, we checked with the previous stake",
      "tokens": [
        50768,
        407,
        300,
        300,
        311,
        983,
        498,
        291,
        528,
        281,
        5623,
        428,
        10407,
        11,
        321,
        10033,
        365,
        264,
        3894,
        10407,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 280,
      "seek": 110830,
      "start": 1121.74,
      "end": 1123.4199999999998,
      "text": " to increase the stake amount.",
      "tokens": [
        51036,
        281,
        3488,
        264,
        10407,
        2372,
        13,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 281,
      "seek": 110830,
      "start": 1123.4199999999998,
      "end": 1124.1399999999999,
      "text": " Right.",
      "tokens": [
        51120,
        1779,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 282,
      "seek": 110830,
      "start": 1124.1399999999999,
      "end": 1126.22,
      "text": " So that's the only reason why I've saved it.",
      "tokens": [
        51156,
        407,
        300,
        311,
        264,
        787,
        1778,
        983,
        286,
        600,
        6624,
        309,
        13,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 283,
      "seek": 110830,
      "start": 1126.22,
      "end": 1133.1,
      "text": " If it was not there, I would have just had an empty PDA maybe with a bump value for prediction",
      "tokens": [
        51260,
        759,
        309,
        390,
        406,
        456,
        11,
        286,
        576,
        362,
        445,
        632,
        364,
        6707,
        430,
        7509,
        1310,
        365,
        257,
        9961,
        2158,
        337,
        17630,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 284,
      "seek": 110830,
      "start": 1133.1,
      "end": 1133.74,
      "text": " estimate.",
      "tokens": [
        51604,
        12539,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14882123153821558,
      "compression_ratio": 1.6234817813765183,
      "no_speech_prob": 0.0002449916210025549
    },
    {
      "id": 285,
      "seek": 113374,
      "start": 1133.74,
      "end": 1139.9,
      "text": " Now, it might feel like it's a very dicey architecture where it's not saved on chain,",
      "tokens": [
        50364,
        823,
        11,
        309,
        1062,
        841,
        411,
        309,
        311,
        257,
        588,
        10313,
        88,
        9482,
        689,
        309,
        311,
        406,
        6624,
        322,
        5021,
        11,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12442468603452046,
      "compression_ratio": 1.6788990825688073,
      "no_speech_prob": 0.006875070743262768
    },
    {
      "id": 286,
      "seek": 113374,
      "start": 1139.9,
      "end": 1145.9,
      "text": " but you can always fetch the transaction and see like if you go on soul scan right now",
      "tokens": [
        50672,
        457,
        291,
        393,
        1009,
        23673,
        264,
        14425,
        293,
        536,
        411,
        498,
        291,
        352,
        322,
        5133,
        11049,
        558,
        586,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12442468603452046,
      "compression_ratio": 1.6788990825688073,
      "no_speech_prob": 0.006875070743262768
    },
    {
      "id": 287,
      "seek": 113374,
      "start": 1145.9,
      "end": 1153.74,
      "text": " and in the setting you paste any ideal and if that ideal has this self CPI, you can pass",
      "tokens": [
        50972,
        293,
        294,
        264,
        3287,
        291,
        9163,
        604,
        7157,
        293,
        498,
        300,
        7157,
        575,
        341,
        2698,
        22431,
        40,
        11,
        291,
        393,
        1320,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12442468603452046,
      "compression_ratio": 1.6788990825688073,
      "no_speech_prob": 0.006875070743262768
    },
    {
      "id": 288,
      "seek": 113374,
      "start": 1153.74,
      "end": 1156.78,
      "text": " it easily and see the prediction value that is being put.",
      "tokens": [
        51364,
        309,
        3612,
        293,
        536,
        264,
        17630,
        2158,
        300,
        307,
        885,
        829,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12442468603452046,
      "compression_ratio": 1.6788990825688073,
      "no_speech_prob": 0.006875070743262768
    },
    {
      "id": 289,
      "seek": 113374,
      "start": 1156.78,
      "end": 1160.7,
      "text": " So it's not like it's not completely on chain.",
      "tokens": [
        51516,
        407,
        309,
        311,
        406,
        411,
        309,
        311,
        406,
        2584,
        322,
        5021,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12442468603452046,
      "compression_ratio": 1.6788990825688073,
      "no_speech_prob": 0.006875070743262768
    },
    {
      "id": 290,
      "seek": 116070,
      "start": 1160.7,
      "end": 1164.38,
      "text": " It's still there in the instruction data or the transaction that you just called.",
      "tokens": [
        50364,
        467,
        311,
        920,
        456,
        294,
        264,
        10951,
        1412,
        420,
        264,
        14425,
        300,
        291,
        445,
        1219,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11151956376575288,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.01358793955296278
    },
    {
      "id": 291,
      "seek": 116070,
      "start": 1165.02,
      "end": 1171.82,
      "text": " And when we resolve the pools, we make sure that the indexer is not lagging.",
      "tokens": [
        50580,
        400,
        562,
        321,
        14151,
        264,
        28688,
        11,
        321,
        652,
        988,
        300,
        264,
        8186,
        260,
        307,
        406,
        8953,
        3249,
        13,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11151956376575288,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.01358793955296278
    },
    {
      "id": 292,
      "seek": 116070,
      "start": 1171.82,
      "end": 1174.38,
      "text": " We're not missing any transactions.",
      "tokens": [
        50920,
        492,
        434,
        406,
        5361,
        604,
        16856,
        13,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11151956376575288,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.01358793955296278
    },
    {
      "id": 293,
      "seek": 116070,
      "start": 1174.38,
      "end": 1176.22,
      "text": " So we make sure of that as well.",
      "tokens": [
        51048,
        407,
        321,
        652,
        988,
        295,
        300,
        382,
        731,
        13,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11151956376575288,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.01358793955296278
    },
    {
      "id": 294,
      "seek": 116070,
      "start": 1176.8600000000001,
      "end": 1183.66,
      "text": " I feel like this architecture is very good for consumer applications and even deepened",
      "tokens": [
        51172,
        286,
        841,
        411,
        341,
        9482,
        307,
        588,
        665,
        337,
        9711,
        5821,
        293,
        754,
        2452,
        5320,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11151956376575288,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.01358793955296278
    },
    {
      "id": 295,
      "seek": 116070,
      "start": 1183.66,
      "end": 1184.94,
      "text": " protocols, right?",
      "tokens": [
        51512,
        20618,
        11,
        558,
        30,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11151956376575288,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.01358793955296278
    },
    {
      "id": 296,
      "seek": 118494,
      "start": 1185.02,
      "end": 1191.18,
      "text": " Where you say if you're like, let's say you're saving certain kind of data on chain for",
      "tokens": [
        50368,
        2305,
        291,
        584,
        498,
        291,
        434,
        411,
        11,
        718,
        311,
        584,
        291,
        434,
        6816,
        1629,
        733,
        295,
        1412,
        322,
        5021,
        337,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22066600348359794,
      "compression_ratio": 1.563063063063063,
      "no_speech_prob": 0.06516531854867935
    },
    {
      "id": 297,
      "seek": 118494,
      "start": 1191.18,
      "end": 1192.94,
      "text": " deep into get rewards.",
      "tokens": [
        50676,
        2452,
        666,
        483,
        17203,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22066600348359794,
      "compression_ratio": 1.563063063063063,
      "no_speech_prob": 0.06516531854867935
    },
    {
      "id": 298,
      "seek": 118494,
      "start": 1192.94,
      "end": 1200.78,
      "text": " So at the end, I feel like have you heard I guess at Helium, they have this library",
      "tokens": [
        50764,
        407,
        412,
        264,
        917,
        11,
        286,
        841,
        411,
        362,
        291,
        2198,
        286,
        2041,
        412,
        6128,
        2197,
        11,
        436,
        362,
        341,
        6405,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22066600348359794,
      "compression_ratio": 1.563063063063063,
      "no_speech_prob": 0.06516531854867935
    },
    {
      "id": 299,
      "seek": 118494,
      "start": 1200.78,
      "end": 1205.66,
      "text": " called Tuk Tuk to like reclaim and I don't remember it quite well.",
      "tokens": [
        51156,
        1219,
        314,
        2034,
        314,
        2034,
        281,
        411,
        40074,
        293,
        286,
        500,
        380,
        1604,
        309,
        1596,
        731,
        13,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22066600348359794,
      "compression_ratio": 1.563063063063063,
      "no_speech_prob": 0.06516531854867935
    },
    {
      "id": 300,
      "seek": 118494,
      "start": 1206.3,
      "end": 1214.46,
      "text": " So cost actually becomes a very big major thing once you scale and you have that many",
      "tokens": [
        51432,
        407,
        2063,
        767,
        3643,
        257,
        588,
        955,
        2563,
        551,
        1564,
        291,
        4373,
        293,
        291,
        362,
        300,
        867,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22066600348359794,
      "compression_ratio": 1.563063063063063,
      "no_speech_prob": 0.06516531854867935
    },
    {
      "id": 301,
      "seek": 121446,
      "start": 1214.46,
      "end": 1219.3400000000001,
      "text": " users and you're making so much you can't keep on storing so much data on chain.",
      "tokens": [
        50364,
        5022,
        293,
        291,
        434,
        1455,
        370,
        709,
        291,
        393,
        380,
        1066,
        322,
        26085,
        370,
        709,
        1412,
        322,
        5021,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 302,
      "seek": 121446,
      "start": 1219.3400000000001,
      "end": 1224.8600000000001,
      "text": " So even if we sponsor fees, we need to make sure that we don't end up sponsoring so much",
      "tokens": [
        50608,
        407,
        754,
        498,
        321,
        16198,
        13370,
        11,
        321,
        643,
        281,
        652,
        988,
        300,
        321,
        500,
        380,
        917,
        493,
        30311,
        370,
        709,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 303,
      "seek": 121446,
      "start": 1224.8600000000001,
      "end": 1230.8600000000001,
      "text": " that our sponsor wallet keeps running out time to time and it doesn't affect the users.",
      "tokens": [
        50884,
        300,
        527,
        16198,
        16599,
        5965,
        2614,
        484,
        565,
        281,
        565,
        293,
        309,
        1177,
        380,
        3345,
        264,
        5022,
        13,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 304,
      "seek": 121446,
      "start": 1231.42,
      "end": 1233.1000000000001,
      "text": " So I don't think so.",
      "tokens": [
        51212,
        407,
        286,
        500,
        380,
        519,
        370,
        13,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 305,
      "seek": 121446,
      "start": 1233.1000000000001,
      "end": 1236.14,
      "text": " There's an issue with the architecture will miss any predictions.",
      "tokens": [
        51296,
        821,
        311,
        364,
        2734,
        365,
        264,
        9482,
        486,
        1713,
        604,
        21264,
        13,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 306,
      "seek": 121446,
      "start": 1237.1000000000001,
      "end": 1241.02,
      "text": " I hope I answered your question because there are like multiple questions.",
      "tokens": [
        51496,
        286,
        1454,
        286,
        10103,
        428,
        1168,
        570,
        456,
        366,
        411,
        3866,
        1651,
        13,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 307,
      "seek": 121446,
      "start": 1241.02,
      "end": 1243.58,
      "text": " If I miss something, you can just let me know.",
      "tokens": [
        51692,
        759,
        286,
        1713,
        746,
        11,
        291,
        393,
        445,
        718,
        385,
        458,
        13,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303524001170013,
      "compression_ratio": 1.7518796992481203,
      "no_speech_prob": 0.0018856121459975839
    },
    {
      "id": 308,
      "seek": 124358,
      "start": 1243.58,
      "end": 1244.62,
      "text": " Do you answer most of it?",
      "tokens": [
        50364,
        1144,
        291,
        1867,
        881,
        295,
        309,
        30,
        50416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 309,
      "seek": 124358,
      "start": 1245.1,
      "end": 1248.62,
      "text": " Is this like common pattern in Solana to log things and not sort them on chain?",
      "tokens": [
        50440,
        1119,
        341,
        411,
        2689,
        5102,
        294,
        7026,
        2095,
        281,
        3565,
        721,
        293,
        406,
        1333,
        552,
        322,
        5021,
        30,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 310,
      "seek": 124358,
      "start": 1248.62,
      "end": 1252.3799999999999,
      "text": " You know, throwing nexus to them or is this something novel that you saw over here?",
      "tokens": [
        50616,
        509,
        458,
        11,
        10238,
        408,
        32618,
        281,
        552,
        420,
        307,
        341,
        746,
        7613,
        300,
        291,
        1866,
        670,
        510,
        30,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 311,
      "seek": 124358,
      "start": 1252.3799999999999,
      "end": 1255.1,
      "text": " I feel like the five protocols do that as well.",
      "tokens": [
        50804,
        286,
        841,
        411,
        264,
        1732,
        20618,
        360,
        300,
        382,
        731,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 312,
      "seek": 124358,
      "start": 1255.1,
      "end": 1260.1399999999999,
      "text": " I might have taken inspiration for some there because I've always looked into like the five",
      "tokens": [
        50940,
        286,
        1062,
        362,
        2726,
        10249,
        337,
        512,
        456,
        570,
        286,
        600,
        1009,
        2956,
        666,
        411,
        264,
        1732,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 313,
      "seek": 124358,
      "start": 1260.1399999999999,
      "end": 1264.06,
      "text": " protocols that are there on chain or if they have open source their code.",
      "tokens": [
        51192,
        20618,
        300,
        366,
        456,
        322,
        5021,
        420,
        498,
        436,
        362,
        1269,
        4009,
        641,
        3089,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 314,
      "seek": 124358,
      "start": 1264.06,
      "end": 1270.54,
      "text": " But I feel like some do like emit CPI logs via the instruction data itself.",
      "tokens": [
        51388,
        583,
        286,
        841,
        411,
        512,
        360,
        411,
        32084,
        22431,
        40,
        20820,
        5766,
        264,
        10951,
        1412,
        2564,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30904855728149416,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.003098160494118929
    },
    {
      "id": 315,
      "seek": 127054,
      "start": 1270.54,
      "end": 1274.3,
      "text": " I realized it later when I was looking at some of the protocols.",
      "tokens": [
        50364,
        286,
        5334,
        309,
        1780,
        562,
        286,
        390,
        1237,
        412,
        512,
        295,
        264,
        20618,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 316,
      "seek": 127054,
      "start": 1274.3,
      "end": 1278.78,
      "text": " I'm not sure if they are critical data, but they might be something which is of use for",
      "tokens": [
        50552,
        286,
        478,
        406,
        988,
        498,
        436,
        366,
        4924,
        1412,
        11,
        457,
        436,
        1062,
        312,
        746,
        597,
        307,
        295,
        764,
        337,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 317,
      "seek": 127054,
      "start": 1279.6599999999999,
      "end": 1281.8999999999999,
      "text": " they might have some indexing services as well.",
      "tokens": [
        50820,
        436,
        1062,
        362,
        512,
        8186,
        278,
        3328,
        382,
        731,
        13,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 318,
      "seek": 127054,
      "start": 1281.8999999999999,
      "end": 1282.3799999999999,
      "text": " All right.",
      "tokens": [
        50932,
        1057,
        558,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 319,
      "seek": 127054,
      "start": 1282.3799999999999,
      "end": 1282.8799999999999,
      "text": " Makes sense.",
      "tokens": [
        50956,
        25245,
        2020,
        13,
        50981
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 320,
      "seek": 127054,
      "start": 1283.98,
      "end": 1288.3799999999999,
      "text": " On that note, I would love to know three, you know, top contracts that you think people",
      "tokens": [
        51036,
        1282,
        300,
        3637,
        11,
        286,
        576,
        959,
        281,
        458,
        1045,
        11,
        291,
        458,
        11,
        1192,
        13952,
        300,
        291,
        519,
        561,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 321,
      "seek": 127054,
      "start": 1288.3799999999999,
      "end": 1289.5,
      "text": " can learn a lot from.",
      "tokens": [
        51256,
        393,
        1466,
        257,
        688,
        490,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 322,
      "seek": 127054,
      "start": 1291.74,
      "end": 1294.46,
      "text": " Three contracts which you could learn from.",
      "tokens": [
        51424,
        6244,
        13952,
        597,
        291,
        727,
        1466,
        490,
        13,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 323,
      "seek": 127054,
      "start": 1295.5,
      "end": 1298.94,
      "text": " I think Camino is open source right now.",
      "tokens": [
        51612,
        286,
        519,
        6886,
        2982,
        307,
        1269,
        4009,
        558,
        586,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2514893381219161,
      "compression_ratio": 1.6561264822134387,
      "no_speech_prob": 0.0035390795674175024
    },
    {
      "id": 324,
      "seek": 129894,
      "start": 1298.94,
      "end": 1299.5,
      "text": " K-Land.",
      "tokens": [
        50364,
        591,
        12,
        43,
        474,
        13,
        50392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 325,
      "seek": 129894,
      "start": 1300.06,
      "end": 1301.66,
      "text": " I've always referred to that.",
      "tokens": [
        50420,
        286,
        600,
        1009,
        10839,
        281,
        300,
        13,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 326,
      "seek": 129894,
      "start": 1301.66,
      "end": 1304.6200000000001,
      "text": " I mean, I used to like look at a lot.",
      "tokens": [
        50500,
        286,
        914,
        11,
        286,
        1143,
        281,
        411,
        574,
        412,
        257,
        688,
        13,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 327,
      "seek": 129894,
      "start": 1304.6200000000001,
      "end": 1305.26,
      "text": " I don't think so.",
      "tokens": [
        50648,
        286,
        500,
        380,
        519,
        370,
        13,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 328,
      "seek": 129894,
      "start": 1305.26,
      "end": 1312.06,
      "text": " It's a very clean architecture wise, but you get to know a lot of things of how like a",
      "tokens": [
        50680,
        467,
        311,
        257,
        588,
        2541,
        9482,
        10829,
        11,
        457,
        291,
        483,
        281,
        458,
        257,
        688,
        295,
        721,
        295,
        577,
        411,
        257,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 329,
      "seek": 129894,
      "start": 1312.06,
      "end": 1318.6200000000001,
      "text": " protocol such as K-Land and stuff write their code and also Squads protocol is very clean.",
      "tokens": [
        51020,
        10336,
        1270,
        382,
        591,
        12,
        43,
        474,
        293,
        1507,
        2464,
        641,
        3089,
        293,
        611,
        8683,
        5834,
        10336,
        307,
        588,
        2541,
        13,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 330,
      "seek": 129894,
      "start": 1318.6200000000001,
      "end": 1322.46,
      "text": " Like their code is at very good quality that you could look at.",
      "tokens": [
        51348,
        1743,
        641,
        3089,
        307,
        412,
        588,
        665,
        3125,
        300,
        291,
        727,
        574,
        412,
        13,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 331,
      "seek": 129894,
      "start": 1322.46,
      "end": 1323.74,
      "text": " So K-Land, Squads.",
      "tokens": [
        51540,
        407,
        591,
        12,
        43,
        474,
        11,
        8683,
        5834,
        13,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 332,
      "seek": 129894,
      "start": 1325.5,
      "end": 1328.6200000000001,
      "text": " Apart from that, yeah, I don't think so.",
      "tokens": [
        51692,
        24111,
        490,
        300,
        11,
        1338,
        11,
        286,
        500,
        380,
        519,
        370,
        13,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.180013311190868,
      "compression_ratio": 1.70995670995671,
      "no_speech_prob": 0.003295706817880273
    },
    {
      "id": 333,
      "seek": 132862,
      "start": 1328.62,
      "end": 1332.3,
      "text": " I would recommend any other contracts apart from these two.",
      "tokens": [
        50364,
        286,
        576,
        2748,
        604,
        661,
        13952,
        4936,
        490,
        613,
        732,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 334,
      "seek": 132862,
      "start": 1332.3,
      "end": 1332.4599999999998,
      "text": " Yeah.",
      "tokens": [
        50548,
        865,
        13,
        50556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 335,
      "seek": 132862,
      "start": 1332.4599999999998,
      "end": 1332.78,
      "text": " All right.",
      "tokens": [
        50556,
        1057,
        558,
        13,
        50572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 336,
      "seek": 132862,
      "start": 1332.78,
      "end": 1335.02,
      "text": " I think I have one more question, which is what's next for Trepar?",
      "tokens": [
        50572,
        286,
        519,
        286,
        362,
        472,
        544,
        1168,
        11,
        597,
        307,
        437,
        311,
        958,
        337,
        8648,
        2181,
        30,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 337,
      "seek": 132862,
      "start": 1335.02,
      "end": 1336.2199999999998,
      "text": " What are you working on right now?",
      "tokens": [
        50684,
        708,
        366,
        291,
        1364,
        322,
        558,
        586,
        30,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 338,
      "seek": 132862,
      "start": 1337.9799999999998,
      "end": 1341.4199999999998,
      "text": " So we're working on something called as Flash Pools.",
      "tokens": [
        50832,
        407,
        321,
        434,
        1364,
        322,
        746,
        1219,
        382,
        20232,
        430,
        29298,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 339,
      "seek": 132862,
      "start": 1341.4199999999998,
      "end": 1344.3799999999999,
      "text": " I guess it's going to come out soon, maybe by the end of the month.",
      "tokens": [
        51004,
        286,
        2041,
        309,
        311,
        516,
        281,
        808,
        484,
        2321,
        11,
        1310,
        538,
        264,
        917,
        295,
        264,
        1618,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 340,
      "seek": 132862,
      "start": 1345.9799999999998,
      "end": 1351.5,
      "text": " It's basically price predictions where you predict in a very shorter window.",
      "tokens": [
        51232,
        467,
        311,
        1936,
        3218,
        21264,
        689,
        291,
        6069,
        294,
        257,
        588,
        11639,
        4910,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 341,
      "seek": 132862,
      "start": 1352.3799999999999,
      "end": 1357.7399999999998,
      "text": " I know people will like to see the price chart move up and down and predict really quick",
      "tokens": [
        51552,
        286,
        458,
        561,
        486,
        411,
        281,
        536,
        264,
        3218,
        6927,
        1286,
        493,
        293,
        760,
        293,
        6069,
        534,
        1702,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1449087654672018,
      "compression_ratio": 1.5870307167235496,
      "no_speech_prob": 0.0005344951641745865
    },
    {
      "id": 342,
      "seek": 135774,
      "start": 1357.74,
      "end": 1361.82,
      "text": " and then just get to know if they want or not instead of waiting for more time.",
      "tokens": [
        50364,
        293,
        550,
        445,
        483,
        281,
        458,
        498,
        436,
        528,
        420,
        406,
        2602,
        295,
        3806,
        337,
        544,
        565,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 343,
      "seek": 135774,
      "start": 1361.82,
      "end": 1365.5,
      "text": " So this is something that we're actively working on right now.",
      "tokens": [
        50568,
        407,
        341,
        307,
        746,
        300,
        321,
        434,
        13022,
        1364,
        322,
        558,
        586,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 344,
      "seek": 135774,
      "start": 1365.5,
      "end": 1365.82,
      "text": " All right.",
      "tokens": [
        50752,
        1057,
        558,
        13,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 345,
      "seek": 135774,
      "start": 1365.82,
      "end": 1368.6200000000001,
      "text": " What is the timeline of this as in the Flash trade?",
      "tokens": [
        50768,
        708,
        307,
        264,
        12933,
        295,
        341,
        382,
        294,
        264,
        20232,
        4923,
        30,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 346,
      "seek": 135774,
      "start": 1368.6200000000001,
      "end": 1370.6200000000001,
      "text": " Like is it I get it every 20 seconds.",
      "tokens": [
        50908,
        1743,
        307,
        309,
        286,
        483,
        309,
        633,
        945,
        3949,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 347,
      "seek": 135774,
      "start": 1370.6200000000001,
      "end": 1372.54,
      "text": " What would the whole price be in the next 20 seconds?",
      "tokens": [
        51008,
        708,
        576,
        264,
        1379,
        3218,
        312,
        294,
        264,
        958,
        945,
        3949,
        30,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 348,
      "seek": 135774,
      "start": 1372.54,
      "end": 1373.66,
      "text": " Something like that.",
      "tokens": [
        51104,
        6595,
        411,
        300,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 349,
      "seek": 135774,
      "start": 1373.66,
      "end": 1378.38,
      "text": " Right now, I'm not sure if it'll change it, but I feel like it's going to be like a two",
      "tokens": [
        51160,
        1779,
        586,
        11,
        286,
        478,
        406,
        988,
        498,
        309,
        603,
        1319,
        309,
        11,
        457,
        286,
        841,
        411,
        309,
        311,
        516,
        281,
        312,
        411,
        257,
        732,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 350,
      "seek": 135774,
      "start": 1378.38,
      "end": 1382.3,
      "text": " minute pool cycle where you predict for one minute, wait for one minute.",
      "tokens": [
        51396,
        3456,
        7005,
        6586,
        689,
        291,
        6069,
        337,
        472,
        3456,
        11,
        1699,
        337,
        472,
        3456,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 351,
      "seek": 135774,
      "start": 1382.3,
      "end": 1385.5,
      "text": " And so you just predict for the next two minutes.",
      "tokens": [
        51592,
        400,
        370,
        291,
        445,
        6069,
        337,
        264,
        958,
        732,
        2077,
        13,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 352,
      "seek": 135774,
      "start": 1385.5,
      "end": 1385.98,
      "text": " Got it.",
      "tokens": [
        51752,
        5803,
        309,
        13,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 353,
      "seek": 135774,
      "start": 1385.98,
      "end": 1386.54,
      "text": " Makes sense.",
      "tokens": [
        51776,
        25245,
        2020,
        13,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18650684971963205,
      "compression_ratio": 1.7515923566878981,
      "no_speech_prob": 0.0004801879695151001
    },
    {
      "id": 354,
      "seek": 138654,
      "start": 1387.18,
      "end": 1390.22,
      "text": " And there's a lot of interesting things like UI wise you could do here.",
      "tokens": [
        50396,
        400,
        456,
        311,
        257,
        688,
        295,
        1880,
        721,
        411,
        15682,
        10829,
        291,
        727,
        360,
        510,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 355,
      "seek": 138654,
      "start": 1391.18,
      "end": 1393.02,
      "text": " Have you seen the tile trading?",
      "tokens": [
        50596,
        3560,
        291,
        1612,
        264,
        20590,
        9529,
        30,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 356,
      "seek": 138654,
      "start": 1396.22,
      "end": 1401.82,
      "text": " Yeah, you can just click on a bunch of tiles and if the line moves your tile, you make money.",
      "tokens": [
        50848,
        865,
        11,
        291,
        393,
        445,
        2052,
        322,
        257,
        3840,
        295,
        21982,
        293,
        498,
        264,
        1622,
        6067,
        428,
        20590,
        11,
        291,
        652,
        1460,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 357,
      "seek": 138654,
      "start": 1402.3799999999999,
      "end": 1403.34,
      "text": " It's quite good.",
      "tokens": [
        51156,
        467,
        311,
        1596,
        665,
        13,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 358,
      "seek": 138654,
      "start": 1403.34,
      "end": 1405.02,
      "text": " Like clicking on small tiles.",
      "tokens": [
        51204,
        1743,
        9697,
        322,
        1359,
        21982,
        13,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 359,
      "seek": 138654,
      "start": 1405.02,
      "end": 1410.22,
      "text": " It's just I think from UI wise, we need to make sure that user knows what they're predicting",
      "tokens": [
        51288,
        467,
        311,
        445,
        286,
        519,
        490,
        15682,
        10829,
        11,
        321,
        643,
        281,
        652,
        988,
        300,
        4195,
        3255,
        437,
        436,
        434,
        32884,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 360,
      "seek": 138654,
      "start": 1410.22,
      "end": 1412.3,
      "text": " and they're just like clicking random things.",
      "tokens": [
        51548,
        293,
        436,
        434,
        445,
        411,
        9697,
        4974,
        721,
        13,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23831280458320692,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.003115758765488863
    },
    {
      "id": 361,
      "seek": 141230,
      "start": 1413.1,
      "end": 1417.18,
      "text": " Ruben has a very whole idea about the UI stuff.",
      "tokens": [
        50404,
        10518,
        268,
        575,
        257,
        588,
        1379,
        1558,
        466,
        264,
        15682,
        1507,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 362,
      "seek": 141230,
      "start": 1417.18,
      "end": 1417.6599999999999,
      "text": " Got it.",
      "tokens": [
        50608,
        5803,
        309,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 363,
      "seek": 141230,
      "start": 1417.6599999999999,
      "end": 1418.1399999999999,
      "text": " Makes sense.",
      "tokens": [
        50632,
        25245,
        2020,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 364,
      "seek": 141230,
      "start": 1418.94,
      "end": 1419.98,
      "text": " How big is the team right now?",
      "tokens": [
        50696,
        1012,
        955,
        307,
        264,
        1469,
        558,
        586,
        30,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 365,
      "seek": 141230,
      "start": 1419.98,
      "end": 1421.26,
      "text": " How many engineers do you have?",
      "tokens": [
        50748,
        1012,
        867,
        11955,
        360,
        291,
        362,
        30,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 366,
      "seek": 141230,
      "start": 1421.26,
      "end": 1425.98,
      "text": " So the entire team is like for full time, we have six people.",
      "tokens": [
        50812,
        407,
        264,
        2302,
        1469,
        307,
        411,
        337,
        1577,
        565,
        11,
        321,
        362,
        2309,
        561,
        13,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 367,
      "seek": 141230,
      "start": 1425.98,
      "end": 1427.1,
      "text": " It's a very small team.",
      "tokens": [
        51048,
        467,
        311,
        257,
        588,
        1359,
        1469,
        13,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 368,
      "seek": 141230,
      "start": 1427.6599999999999,
      "end": 1432.46,
      "text": " And for technical engineering side of us, there's me, there's Ruben, then there's our",
      "tokens": [
        51132,
        400,
        337,
        6191,
        7043,
        1252,
        295,
        505,
        11,
        456,
        311,
        385,
        11,
        456,
        311,
        10518,
        268,
        11,
        550,
        456,
        311,
        527,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 369,
      "seek": 141230,
      "start": 1432.46,
      "end": 1433.74,
      "text": " CTO Leon.",
      "tokens": [
        51372,
        383,
        15427,
        13244,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 370,
      "seek": 141230,
      "start": 1433.74,
      "end": 1440.54,
      "text": " So we all three work together to ship things fast and I think we are doing good at this point.",
      "tokens": [
        51436,
        407,
        321,
        439,
        1045,
        589,
        1214,
        281,
        5374,
        721,
        2370,
        293,
        286,
        519,
        321,
        366,
        884,
        665,
        412,
        341,
        935,
        13,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 371,
      "seek": 141230,
      "start": 1440.54,
      "end": 1441.02,
      "text": " Got it.",
      "tokens": [
        51776,
        5803,
        309,
        13,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1450526863336563,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.043186068534851074
    },
    {
      "id": 372,
      "seek": 144102,
      "start": 1441.02,
      "end": 1445.82,
      "text": " And in the future, if you're ever hiring, what should people expect in the interview",
      "tokens": [
        50364,
        400,
        294,
        264,
        2027,
        11,
        498,
        291,
        434,
        1562,
        15335,
        11,
        437,
        820,
        561,
        2066,
        294,
        264,
        4049,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 373,
      "seek": 144102,
      "start": 1445.82,
      "end": 1446.1399999999999,
      "text": " process?",
      "tokens": [
        50604,
        1399,
        30,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 374,
      "seek": 144102,
      "start": 1446.1399999999999,
      "end": 1449.26,
      "text": " What should they have their resume to be able to get an interview at Trava?",
      "tokens": [
        50620,
        708,
        820,
        436,
        362,
        641,
        15358,
        281,
        312,
        1075,
        281,
        483,
        364,
        4049,
        412,
        5403,
        2757,
        30,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 375,
      "seek": 144102,
      "start": 1450.7,
      "end": 1456.54,
      "text": " If there's any role that you feel like would help Trappa, you could always DM or see you on",
      "tokens": [
        50848,
        759,
        456,
        311,
        604,
        3090,
        300,
        291,
        841,
        411,
        576,
        854,
        5403,
        34827,
        11,
        291,
        727,
        1009,
        15322,
        420,
        536,
        291,
        322,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 376,
      "seek": 144102,
      "start": 1456.54,
      "end": 1462.54,
      "text": " Telegram or Twitter or maybe just DM me if I see something I could always forward.",
      "tokens": [
        51140,
        14889,
        1342,
        420,
        5794,
        420,
        1310,
        445,
        15322,
        385,
        498,
        286,
        536,
        746,
        286,
        727,
        1009,
        2128,
        13,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 377,
      "seek": 144102,
      "start": 1463.82,
      "end": 1467.02,
      "text": " For hiring, I don't think so.",
      "tokens": [
        51504,
        1171,
        15335,
        11,
        286,
        500,
        380,
        519,
        370,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 378,
      "seek": 144102,
      "start": 1467.02,
      "end": 1469.74,
      "text": " We have done like an official hiring where we announced it.",
      "tokens": [
        51664,
        492,
        362,
        1096,
        411,
        364,
        4783,
        15335,
        689,
        321,
        7548,
        309,
        13,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.155253995928848,
      "compression_ratio": 1.643939393939394,
      "no_speech_prob": 0.0037670026067644358
    },
    {
      "id": 379,
      "seek": 146974,
      "start": 1469.74,
      "end": 1476.46,
      "text": " It's always been like I met the co-founder, John, at network school last year and I got",
      "tokens": [
        50364,
        467,
        311,
        1009,
        668,
        411,
        286,
        1131,
        264,
        598,
        12,
        33348,
        11,
        2619,
        11,
        412,
        3209,
        1395,
        1036,
        1064,
        293,
        286,
        658,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 380,
      "seek": 146974,
      "start": 1476.46,
      "end": 1480.54,
      "text": " involved as a contract with work first and then I got offered the full time role.",
      "tokens": [
        50700,
        3288,
        382,
        257,
        4364,
        365,
        589,
        700,
        293,
        550,
        286,
        658,
        8059,
        264,
        1577,
        565,
        3090,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 381,
      "seek": 146974,
      "start": 1481.34,
      "end": 1485.18,
      "text": " For Ruben, I guess I referred him via someone.",
      "tokens": [
        50944,
        1171,
        10518,
        268,
        11,
        286,
        2041,
        286,
        10839,
        796,
        5766,
        1580,
        13,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 382,
      "seek": 146974,
      "start": 1485.18,
      "end": 1488.7,
      "text": " So it's very unofficial process.",
      "tokens": [
        51136,
        407,
        309,
        311,
        588,
        8526,
        37661,
        1399,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 383,
      "seek": 146974,
      "start": 1488.7,
      "end": 1494.38,
      "text": " But if there's something that you could help out with us, just reach out to John on his",
      "tokens": [
        51312,
        583,
        498,
        456,
        311,
        746,
        300,
        291,
        727,
        854,
        484,
        365,
        505,
        11,
        445,
        2524,
        484,
        281,
        2619,
        322,
        702,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 384,
      "seek": 146974,
      "start": 1494.38,
      "end": 1494.78,
      "text": " Twitter.",
      "tokens": [
        51596,
        5794,
        13,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 385,
      "seek": 146974,
      "start": 1495.82,
      "end": 1496.3,
      "text": " Got it.",
      "tokens": [
        51668,
        5803,
        309,
        13,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21274394989013673,
      "compression_ratio": 1.5128205128205128,
      "no_speech_prob": 0.0007857755990698934
    },
    {
      "id": 386,
      "seek": 149630,
      "start": 1496.94,
      "end": 1500.06,
      "text": " I'm assuming that you didn't have an interview process, but you do have an interview process.",
      "tokens": [
        50396,
        286,
        478,
        11926,
        300,
        291,
        994,
        380,
        362,
        364,
        4049,
        1399,
        11,
        457,
        291,
        360,
        362,
        364,
        4049,
        1399,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 387,
      "seek": 149630,
      "start": 1500.06,
      "end": 1502.22,
      "text": " Do you generally have an interview process for new engineers?",
      "tokens": [
        50552,
        1144,
        291,
        5101,
        362,
        364,
        4049,
        1399,
        337,
        777,
        11955,
        30,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 388,
      "seek": 149630,
      "start": 1504.22,
      "end": 1509.18,
      "text": " I mean, yeah, if we hire again, we'll have an interview process.",
      "tokens": [
        50760,
        286,
        914,
        11,
        1338,
        11,
        498,
        321,
        11158,
        797,
        11,
        321,
        603,
        362,
        364,
        4049,
        1399,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 389,
      "seek": 149630,
      "start": 1509.18,
      "end": 1514.3799999999999,
      "text": " For me, I got started helping them with something related to decentralizing their work",
      "tokens": [
        51008,
        1171,
        385,
        11,
        286,
        658,
        1409,
        4315,
        552,
        365,
        746,
        4077,
        281,
        26515,
        3319,
        641,
        589,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 390,
      "seek": 149630,
      "start": 1514.3799999999999,
      "end": 1515.1,
      "text": " flow.",
      "tokens": [
        51268,
        3095,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 391,
      "seek": 149630,
      "start": 1515.1,
      "end": 1517.74,
      "text": " And then I had few calls with them back and forth.",
      "tokens": [
        51304,
        400,
        550,
        286,
        632,
        1326,
        5498,
        365,
        552,
        646,
        293,
        5220,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 392,
      "seek": 149630,
      "start": 1517.74,
      "end": 1521.18,
      "text": " There was no particular like technical round per se.",
      "tokens": [
        51436,
        821,
        390,
        572,
        1729,
        411,
        6191,
        3098,
        680,
        369,
        13,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19579212482158953,
      "compression_ratio": 1.774468085106383,
      "no_speech_prob": 0.008771812543272972
    },
    {
      "id": 393,
      "seek": 152118,
      "start": 1521.26,
      "end": 1526.94,
      "text": " It was mostly discussion on how I think things could be implemented or what kind of",
      "tokens": [
        50368,
        467,
        390,
        5240,
        5017,
        322,
        577,
        286,
        519,
        721,
        727,
        312,
        12270,
        420,
        437,
        733,
        295,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 394,
      "seek": 152118,
      "start": 1526.94,
      "end": 1528.6200000000001,
      "text": " architecture I can use.",
      "tokens": [
        50652,
        9482,
        286,
        393,
        764,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 395,
      "seek": 152118,
      "start": 1528.6200000000001,
      "end": 1533.42,
      "text": " So I believe there was no technical DSA round or a coding round as such.",
      "tokens": [
        50736,
        407,
        286,
        1697,
        456,
        390,
        572,
        6191,
        413,
        8886,
        3098,
        420,
        257,
        17720,
        3098,
        382,
        1270,
        13,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 396,
      "seek": 152118,
      "start": 1534.7,
      "end": 1535.1000000000001,
      "text": " Got it.",
      "tokens": [
        51040,
        5803,
        309,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 397,
      "seek": 152118,
      "start": 1535.98,
      "end": 1539.5,
      "text": " But if someone joins now, they'd probably expect to go through a standard interview",
      "tokens": [
        51104,
        583,
        498,
        1580,
        24397,
        586,
        11,
        436,
        1116,
        1391,
        2066,
        281,
        352,
        807,
        257,
        3832,
        4049,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 398,
      "seek": 152118,
      "start": 1539.5,
      "end": 1539.9,
      "text": " process.",
      "tokens": [
        51280,
        1399,
        13,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 399,
      "seek": 152118,
      "start": 1540.6200000000001,
      "end": 1541.66,
      "text": " Yeah, I don't think so.",
      "tokens": [
        51336,
        865,
        11,
        286,
        500,
        380,
        519,
        370,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 400,
      "seek": 152118,
      "start": 1541.66,
      "end": 1547.5800000000002,
      "text": " There will be a DSA round, but yeah, maybe a take away home assignment or building",
      "tokens": [
        51388,
        821,
        486,
        312,
        257,
        413,
        8886,
        3098,
        11,
        457,
        1338,
        11,
        1310,
        257,
        747,
        1314,
        1280,
        15187,
        420,
        2390,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 401,
      "seek": 152118,
      "start": 1547.5800000000002,
      "end": 1547.98,
      "text": " something.",
      "tokens": [
        51684,
        746,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 402,
      "seek": 152118,
      "start": 1548.54,
      "end": 1549.02,
      "text": " Got it.",
      "tokens": [
        51732,
        5803,
        309,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 403,
      "seek": 152118,
      "start": 1549.02,
      "end": 1549.5,
      "text": " Makes sense.",
      "tokens": [
        51756,
        25245,
        2020,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1641317302897825,
      "compression_ratio": 1.5613382899628252,
      "no_speech_prob": 0.03461339324712753
    },
    {
      "id": 404,
      "seek": 154950,
      "start": 1550.14,
      "end": 1551.34,
      "text": " That's all the questions I had.",
      "tokens": [
        50396,
        663,
        311,
        439,
        264,
        1651,
        286,
        632,
        13,
        50456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 405,
      "seek": 154950,
      "start": 1551.34,
      "end": 1553.1,
      "text": " Thank you so much, Anam for your time.",
      "tokens": [
        50456,
        1044,
        291,
        370,
        709,
        11,
        1107,
        335,
        337,
        428,
        565,
        13,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 406,
      "seek": 154950,
      "start": 1553.1,
      "end": 1555.42,
      "text": " Is there anything else you'd like to add for the audience?",
      "tokens": [
        50544,
        1119,
        456,
        1340,
        1646,
        291,
        1116,
        411,
        281,
        909,
        337,
        264,
        4034,
        30,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 407,
      "seek": 154950,
      "start": 1555.42,
      "end": 1559.82,
      "text": " People who are currently thinking of getting into Solana or specifically want to be",
      "tokens": [
        50660,
        3432,
        567,
        366,
        4362,
        1953,
        295,
        1242,
        666,
        7026,
        2095,
        420,
        4682,
        528,
        281,
        312,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 408,
      "seek": 154950,
      "start": 1559.82,
      "end": 1563.98,
      "text": " maybe blockchain engineers or smart contract engineers because it's hard to find people",
      "tokens": [
        50880,
        1310,
        17176,
        11955,
        420,
        4069,
        4364,
        11955,
        570,
        309,
        311,
        1152,
        281,
        915,
        561,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 409,
      "seek": 154950,
      "start": 1563.98,
      "end": 1565.66,
      "text": " who specifically work on smart contracts.",
      "tokens": [
        51088,
        567,
        4682,
        589,
        322,
        4069,
        13952,
        13,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 410,
      "seek": 154950,
      "start": 1566.86,
      "end": 1572.54,
      "text": " For me, I would say like if you are someone who's getting started particularly in writing",
      "tokens": [
        51232,
        1171,
        385,
        11,
        286,
        576,
        584,
        411,
        498,
        291,
        366,
        1580,
        567,
        311,
        1242,
        1409,
        4098,
        294,
        3579,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 411,
      "seek": 154950,
      "start": 1572.54,
      "end": 1576.22,
      "text": " Solana smart contracts, just start with anchor.",
      "tokens": [
        51516,
        7026,
        2095,
        4069,
        13952,
        11,
        445,
        722,
        365,
        18487,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17981504139147306,
      "compression_ratio": 1.6996466431095407,
      "no_speech_prob": 0.002290749689564109
    },
    {
      "id": 412,
      "seek": 157622,
      "start": 1576.3,
      "end": 1581.9,
      "text": " You don't have to go through the steep learning curve of learning Rust by heart or",
      "tokens": [
        50368,
        509,
        500,
        380,
        362,
        281,
        352,
        807,
        264,
        16841,
        2539,
        7605,
        295,
        2539,
        34952,
        538,
        1917,
        420,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 413,
      "seek": 157622,
      "start": 1581.9,
      "end": 1586.46,
      "text": " something or just follow some basic tutorials in Rust.",
      "tokens": [
        50648,
        746,
        420,
        445,
        1524,
        512,
        3875,
        17616,
        294,
        34952,
        13,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 414,
      "seek": 157622,
      "start": 1586.46,
      "end": 1587.5,
      "text": " Start with anchor.",
      "tokens": [
        50876,
        6481,
        365,
        18487,
        13,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 415,
      "seek": 157622,
      "start": 1587.5,
      "end": 1593.1000000000001,
      "text": " It's a very good framework and a lot of good protocols you use it because it's good for",
      "tokens": [
        50928,
        467,
        311,
        257,
        588,
        665,
        8388,
        293,
        257,
        688,
        295,
        665,
        20618,
        291,
        764,
        309,
        570,
        309,
        311,
        665,
        337,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 416,
      "seek": 157622,
      "start": 1593.1000000000001,
      "end": 1594.6200000000001,
      "text": " consumer applications, right?",
      "tokens": [
        51208,
        9711,
        5821,
        11,
        558,
        30,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 417,
      "seek": 157622,
      "start": 1594.6200000000001,
      "end": 1598.7,
      "text": " Unless until you reach that level where you need to optimize everything by computer",
      "tokens": [
        51284,
        16581,
        1826,
        291,
        2524,
        300,
        1496,
        689,
        291,
        643,
        281,
        19719,
        1203,
        538,
        3820,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 418,
      "seek": 157622,
      "start": 1598.7,
      "end": 1602.7,
      "text": " nets, then go with Pinocchio or native Rust or something like that.",
      "tokens": [
        51488,
        36170,
        11,
        550,
        352,
        365,
        22619,
        905,
        31033,
        420,
        8470,
        34952,
        420,
        746,
        411,
        300,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.128296225678687,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0052672578021883965
    },
    {
      "id": 419,
      "seek": 160270,
      "start": 1602.7,
      "end": 1607.9,
      "text": " But if you start optimizing at just beginner level where you're still learning Rust and",
      "tokens": [
        50364,
        583,
        498,
        291,
        722,
        40425,
        412,
        445,
        22080,
        1496,
        689,
        291,
        434,
        920,
        2539,
        34952,
        293,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 420,
      "seek": 160270,
      "start": 1607.9,
      "end": 1611.9,
      "text": " you're writing like Pinocchio, you'll just end up confusing yourself.",
      "tokens": [
        50624,
        291,
        434,
        3579,
        411,
        22619,
        905,
        31033,
        11,
        291,
        603,
        445,
        917,
        493,
        13181,
        1803,
        13,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 421,
      "seek": 160270,
      "start": 1611.9,
      "end": 1612.8600000000001,
      "text": " Start with anchor.",
      "tokens": [
        50824,
        6481,
        365,
        18487,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 422,
      "seek": 160270,
      "start": 1612.8600000000001,
      "end": 1613.74,
      "text": " Make something work.",
      "tokens": [
        50872,
        4387,
        746,
        589,
        13,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 423,
      "seek": 160270,
      "start": 1613.74,
      "end": 1619.82,
      "text": " When something clicks, you get more excited and you start looking into how to optimize",
      "tokens": [
        50916,
        1133,
        746,
        18521,
        11,
        291,
        483,
        544,
        2919,
        293,
        291,
        722,
        1237,
        666,
        577,
        281,
        19719,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 424,
      "seek": 160270,
      "start": 1619.82,
      "end": 1620.7,
      "text": " this now, right?",
      "tokens": [
        51220,
        341,
        586,
        11,
        558,
        30,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 425,
      "seek": 160270,
      "start": 1620.7,
      "end": 1623.74,
      "text": " So for it's a very niche user base.",
      "tokens": [
        51264,
        407,
        337,
        309,
        311,
        257,
        588,
        19956,
        4195,
        3096,
        13,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 426,
      "seek": 160270,
      "start": 1623.74,
      "end": 1628.06,
      "text": " So I'm just saying that if you're looking into writing Solana smart contracts, start",
      "tokens": [
        51416,
        407,
        286,
        478,
        445,
        1566,
        300,
        498,
        291,
        434,
        1237,
        666,
        3579,
        7026,
        2095,
        4069,
        13952,
        11,
        722,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 427,
      "seek": 160270,
      "start": 1628.06,
      "end": 1630.22,
      "text": " with anchor framework.",
      "tokens": [
        51632,
        365,
        18487,
        8388,
        13,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 428,
      "seek": 160270,
      "start": 1630.22,
      "end": 1630.7,
      "text": " Got it.",
      "tokens": [
        51740,
        5803,
        309,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 429,
      "seek": 160270,
      "start": 1630.7,
      "end": 1632.06,
      "text": " Makes sense on that note.",
      "tokens": [
        51764,
        25245,
        2020,
        322,
        300,
        3637,
        13,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12825396704295325,
      "compression_ratio": 1.7107142857142856,
      "no_speech_prob": 0.01286841370165348
    },
    {
      "id": 430,
      "seek": 163206,
      "start": 1632.06,
      "end": 1633.5,
      "text": " Thank you so much for your time.",
      "tokens": [
        50364,
        1044,
        291,
        370,
        709,
        337,
        428,
        565,
        13,
        50436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28412276373969186,
      "compression_ratio": 1.2586206896551724,
      "no_speech_prob": 0.007690547965466976
    },
    {
      "id": 431,
      "seek": 163206,
      "start": 1633.5,
      "end": 1637.34,
      "text": " Hopefully it was an interesting part for the audience and we'll see you guys in the next",
      "tokens": [
        50436,
        10429,
        309,
        390,
        364,
        1880,
        644,
        337,
        264,
        4034,
        293,
        321,
        603,
        536,
        291,
        1074,
        294,
        264,
        958,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28412276373969186,
      "compression_ratio": 1.2586206896551724,
      "no_speech_prob": 0.007690547965466976
    },
    {
      "id": 432,
      "seek": 163206,
      "start": 1637.34,
      "end": 1637.6599999999999,
      "text": " one.",
      "tokens": [
        50628,
        472,
        13,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28412276373969186,
      "compression_ratio": 1.2586206896551724,
      "no_speech_prob": 0.007690547965466976
    },
    {
      "id": 433,
      "seek": 163206,
      "start": 1637.6599999999999,
      "end": 1638.1399999999999,
      "text": " Thank you.",
      "tokens": [
        50644,
        1044,
        291,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28412276373969186,
      "compression_ratio": 1.2586206896551724,
      "no_speech_prob": 0.007690547965466976
    },
    {
      "id": 434,
      "seek": 163206,
      "start": 1638.1399999999999,
      "end": 1638.94,
      "text": " Bye bye.",
      "tokens": [
        50668,
        4621,
        6543,
        13,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28412276373969186,
      "compression_ratio": 1.2586206896551724,
      "no_speech_prob": 0.007690547965466976
    }
  ],
  "language": "en"
}