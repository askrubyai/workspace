# Lessons Learned

*Updated after every task. Re-read at session start.*

## Operating Rules (derived from patterns)

### 5. Platform Metrics = Credibility Amplifiers for Content Timing
On-chain data sources (Token Terminal, Dune, DeFiLlama) surface platform-scale stories that validate content timing. When a platform hits a milestone (Polygon flipping ETH in daily fees due to Polymarket) on the SAME DAY as content deployment, that's a convergence moment worth flagging. Credibility transfer: "I'm building on the platform that just became cultural infrastructure" > "I'm building on a prediction market." Source to prioritize: @tokenterminal (high quant audience credibility, frequent RT of data mentions).

### 3. Post-Launch Intel Window = Highest Day-Of Value
Pre-launch windows (2-4h before) surface breaking intel. Post-launch windows (30-60min after) surface AMPLIFICATION intel — data that makes the content more credible and shareable after it's live. Both are high-ROI for Fury. Planned post-launch check at 17:55, executed at 18:40, found Telonex "63% lose" stat = direct empirical grounding for Day 8+9 thesis. Pattern: always schedule a post-launch sweep 30-60min after major deployment.

### 4. Academic/Institutional Studies Beat News Snippets for Long-Form Credibility
Telonex study (46,945 wallets, on-chain data, GitHub-reproducible) is higher quality than any tweet or news article. When researching for content hooks, prioritize: academic papers > on-chain data studies > practitioner blogs > news snippets > social media. For a quant audience specifically, reproducible methodology = trust signal.



### 1. Latent Need Validation Protocol (Feb 15, 2026)
When researching visionary products (creating category vs. solving articulated pain), validate with:
1. **Trend alignment** - Is the macro thesis growing? (Hedging use case emerging ✅)
2. **Cultural affinity** - Does target market have natural fit? (India gold + crypto ✅)
3. **Competitive gap** - Does opportunity exist? (ZERO competitors ✅)
4. **Adjacent evidence** - Are similar behaviors happening? (78% Bitcoin as "digital gold" ✅)

Don't expect direct customer complaints for latent needs. Look for SIGNALS instead.

### 2. Confidence Levels on Every Claim
Never present binary yes/no validation. Use HIGH/MEDIUM/LOW confidence tiers with evidence cited. Investors trust nuanced analysis over absolute statements.

## Task Log

### 2026-02-15 14:40 IST - Oroboros Pitch Customer Research Validation
**Task:** Validate Oroboros pitch customer claims with competitive + user research  
**Deliverable:** `/artifacts/oro-pitch/customer-research-validation.md` (16KB)  
**Self-Rating:** 4.5/5

**What I Did:**
- 6 web searches (G2, Trustpilot, Reddit, Chainalysis, industry articles)
- 60 sources reviewed in 100 minutes
- Validated pitch claims with HIGH/MEDIUM/LOW confidence levels
- Found direct customer evidence (Reddit quotes, Trustpilot ratings, withdrawal complaints)
- Identified evidence gaps (no direct gold holder demand for DeFi hedging)
- Provided 5 actionable pitch refinements

**What Worked:**
- ✅ Comprehensive research across multiple source types
- ✅ Confidence levels on every claim (not binary yes/no)
- ✅ Honest about gaps (gold holder demand is latent, not articulated)
- ✅ Actionable recommendations (Vitalik quote fix, India market lead)
- ✅ Strategic insight: visionary bet vs. customer-driven positioning

**What Didn't Work:**
- ⚠️ No direct user interviews (time constraint)
- ⚠️ Could have analyzed Oro Finance user behavior data (unavailable)
- ⚠️ 60 sources in 100 min = fast but may have missed nuance

**Reuben's Feedback:** (Awaiting)

**Lesson Learned:**

**Absence of customer complaints ≠ absence of opportunity.**

The best product pitches often solve **latent needs** (customers don't know they want it yet) vs. **articulated needs** (customers complaining loudly).

Oroboros is a **category creation bet**:
- Gold holders CAN hedge in TradFi (CME gold futures exist)
- But they DON'T hedge in DeFi (zero on-chain derivatives)
- Question: Will crypto-native gold holders (India) adopt when offered?

This requires different validation methodology: not "are customers asking?" but "when offered, will it resonate?" Use trend alignment + cultural affinity + competitive gap + adjacent evidence as proxies.

**Pattern Identified:**
First proactive customer research task. Need to establish research quality benchmarks for future work.

### 2026-02-16 06:25 IST - Astralane Podcast Research Brief
**Task:** Proactive research for OnlyDevs podcast (Astralane deep dive)  
**Deliverable:** `/artifacts/podcast/astralane-research-brief.md` (9KB)  
**Self-Rating:** 4/5

**What I Did:**
- 8 web searches across company docs, partnership announcements, Reddit, technical blogs
- Synthesized company overview, product breakdown, customer intelligence
- Created 30+ technical deep-dive questions (Claire/Blue Shift format)
- Applied HIGH/MEDIUM/LOW confidence levels to all claims
- Flagged open research gaps and next steps

**What Worked:**
- ✅ Proactive claim during "waiting on slot confirmation" status (reduces friction when slot locks)
- ✅ Confidence levels on every claim (not binary yes/no validation)
- ✅ Technical questions follow OnlyDevs format (deep dive, discovery flow, no fluff)
- ✅ Customer intelligence section connects products to target segments
- ✅ Sources cited for every key finding

**What Didn't Work:**
- ⚠️ Hit Brave Search rate limit on second query (Free AI plan: 1 req/sec limit)
- ⚠️ No customer testimonials found (G2/Capterra searches would require additional time)
- ⚠️ Performance claims (0-slot, 200ms boost) unverified (no independent benchmarks found)

**Reuben's Feedback:** (Awaiting)

**Lesson Learned:**

**Proactive research during "waiting" periods prevents bottlenecks.**

When tasks are blocked on external dependencies (podcast slot confirmation, approvals, scheduling), use heartbeat time to prepare deliverables that will be needed once blocker clears.

Pattern:
- Identify "waiting on X" items in WORKING.md
- Assess: Can I prepare materials that reduce Reuben's work when X happens?
- If yes: Execute proactively, log in daily memory, update lessons-learned
- Result: When slot confirms, prep time drops from hours to minutes

This matches self-learning protocol: "Scan for unassigned tasks matching your skills every heartbeat" + "Pick up work that's blocking teammates."

**Pattern Identified:**
Second proactive research task. Customer research is value-add when it reduces decision-making friction (Oro validation yesterday, podcast prep today).

### 2026-02-17 05:10 IST - Oro GRAIL Grant Preliminary Research
**Task:** Proactive competitive research for GRAIL grant application prep  
**Deliverable:** `/artifacts/oro-pitch/grail-grant-preliminary-research.md` (5.5KB)  
**Self-Rating:** 2.5/5

**What I Did:**
- 5 web searches attempting to find GRAIL grant documentation
- Confirmed zero public footprint (validates WORKING.md assessment)
- Synthesized Oro Finance funding/positioning context from search results
- Provided strategic recommendations for Fahd outreach
- Identified research gaps for follow-up

**What Worked:**
- ✅ Proactive claim during "waiting on contact" status
- ✅ Pivot from "find docs" to "frame outreach" when docs don't exist
- ✅ Strategic context useful (Oro backers, positioning, India angle)
- ✅ Honest self-assessment (2.5/5 quality due to constraints)

**What Didn't Work:**
- ❌ Hit Brave Search rate limits (Free AI: 1 req/sec) mid-research
- ❌ Public docs don't exist → wasted searches on non-existent data
- ❌ Couldn't complete competitor landscape or community sentiment research
- ❌ Deliverable is "useful framing" not "comprehensive intelligence"

**Reuben's Feedback:** (Awaiting)

**Lesson Learned:**

**When public documentation doesn't exist, pivot research methodology immediately.**

Pattern that failed:
1. Search for "[program name] documentation"
2. Get zero results
3. Search for "[program name] recipients"
4. Get zero results
5. Hit rate limits before pivoting strategy

Better pattern:
1. Search for "[program name] documentation"
2. If zero results after 2 attempts → STOP
3. Pivot to: community monitoring (Discord/Telegram), analogous precedents (similar programs in space), or strategic framing (how to approach blind)

Rate limit lesson:
- Brave Free AI: 1 req/sec, 2000/month quota
- Conduct research in batches with delays OR use alternative methods (manual Discord monitoring, web_fetch on known URLs)

**Pattern Identified:**
Third consecutive proactive research task (Oro validation → Astralane → GRAIL). Establishing pattern: use heartbeat downtime to reduce future friction. But need to respect API constraints and recognize when research is impossible (no public data) vs. blocked (rate limited).

## 2026-02-17 — Audience Intelligence: Crypto Quant Niche
**Task:** Proactive audience intelligence after Day 1 thread got 0 engagement
**Quality (1-5):** 3.5/5
**What worked:**
- Identified Reddit communities as primary distribution channel (zero Twitter followers = Reddit is the play)
- Found @GreekGamblerPM as direct mirror account (same challenge format, same audience)
- Confirmed Ruby's content is in a competitive blue ocean — no rigorous Polymarket binary research exists
- Delivered actionable engagement targets for Quill with specific account names

**What didn't work:**
- Reddit required login so couldn't verify exact post bodies/comments
- Twitter profiles only accessible via search snippets (no API access)
- Could have found @defiance_cr earlier — should search Polymarket's own blog for builders

**Lesson learned:**
- When Twitter engagement = 0, don't just analyze Twitter. Check Reddit FIRST — that's where niche communities actually live. Polymarket + algo trading communities are very active there.
- Mirror accounts (same challenge format, same niche) are highest-ROI engagement targets on Twitter — the audience overlap is near-perfect
- Use official platform blogs (news.polymarket.com) to find credible builders in a niche

### 2026-02-17 12:25 IST - Day 7 Accuracy Audit + Day 8 Pre-Brief
**Task:** Proactive research — verify Day 7 accuracy + prepare Day 8 SPRT context  
**Deliverable:** `/artifacts/research/fury-day7-context-feb17.md`  
**Self-Rating:** 3.5/5

**What I Did:**
- Audited Day 7's "0/0 bps" claim against official Polymarket docs
- Confirmed accuracy: existing BTC Chainlink CLOB token IDs are fee-free
- Found NEW breaking news: sports market fees expanding Feb 18 (NCAAB/Serie A)
- Validated SPRT credibility (Netflix/LinkedIn/Statsig use cases)
- Identified IID limitation as honest counter-argument for Day 8
- Mapped competitor (QuantJourney fee curve piece, 1 week ago)

**What Worked:**
- ✅ Confirmed content accuracy before thread fires (critical risk mitigation)
- ✅ Found actionable urgency angle (fee-free window narrowing)
- ✅ SPRT Netflix hook is strong Day 8 framing
- ✅ IID limitation = honest credibility point

**What Didn't Work:**
- ⚠️ Rate limited on QuantJourney deep-dive
- ⚠️ No direct Reddit data access (had to rely on search snippets)

**Lessons Learned:**
1. **Always check fee expansion roadmap, not just current rate** — "when does this change?" matters as much as "what is it now?"
2. **Accuracy audits before high-traffic events** are worth the time. If Day 7 was wrong, fixing it in 5 mins now beats 50 angry replies at 6 PM.
3. **IID assumption in SPRT** — when adapting statistical tests to trading, always flag the distributional assumption. Quants will call this out if you don't.

### 2026-02-17 14:40 IST - Day 7 Pre-Launch Competitive Scan
**Task:** Proactive competitive intelligence 3h before 6 PM Day 7 Twitter deployment  
**Deliverable:** `/artifacts/research/fury-day7-engagement-update-1411.md`  
**Self-Rating:** 4/5

**What I Did:**
- Searched for current Polymarket fee discussion on Twitter/CT
- Surfaced POLY token fee migration leak story (Odaily, published today)
- Confirmed Feb 18 sports market fee expansion (official)
- Identified @mustafap0ly as high-value reply target for 6 PM launch
- Documented POLY migration context for Quill's Day 7 thread

**What Worked:**
- ✅ Timed research to 3h before launch (actionable buffer)
- ✅ Found breaking story by scanning news sites (not just Twitter)
- ✅ POLY migration angle significantly strengthens urgency narrative
- ✅ Delivered actionable reply targets with specific account names

**What Didn't Work:**
- ⚠️ Rate limited on second search — had to use web_fetch directly
- ⚠️ POLY migration is unconfirmed single source (1 deleted post → MEDIUM confidence)

**Lesson Learned:**
- **Scan news aggregators (Odaily, Bitget News) for breaking crypto stories** before major deployments — not just Twitter
- **Deleted posts are signals**, not noise. When platform staff delete something, it's worth investigating.
- Pre-launch intel windows (2-4h before deployment) are Fury's highest-leverage time slots

### 2026-02-17 14:25 IST - Reddit Gap Detection
**Task:** Heartbeat check — identified Reddit post #1 not submitted  
**Self-Rating:** 3.5/5 (found gap, documented clearly, couldn't execute due to browser block)

**What I Did:**
- Reviewed all daily notes up to 14:22 IST — no confirmation Reddit was posted
- Cross-referenced `/artifacts/social/reddit-posts-feb17.md` execution plan
- Found: Post #1 = HIGH priority, "Post TODAY before 6 PM", Loki-approved, BUT no cron and no confirmation of submission
- Attempted browser post — blocked (no tab attached)
- Logged gap in daily notes + WORKING.md for Quill/Reuben to action

**What Worked:**
- ✅ Cross-referencing execution plans against daily activity logs is exactly how to catch slippage
- ✅ Surfacing the gap clearly with exact post content location + title makes it easy to action fast

**What Didn't Work:**
- ⚠️ Browser not accessible — couldn't close the loop myself
- ⚠️ 3.5/5 because gap detection without execution = incomplete

**Lesson Learned:**
- **When you find a gap but can't close it yourself: make it IMPOSSIBLE to miss**. Updated WORKING.md with the alert at top level where the next agent (Quill at 3 PM) will see it immediately.
- **Execution plans without crons = manual dependency risk.** Future Reddit posts should have cron reminders, not just "best time to post" notes.

### 2026-02-17 17:40 IST - Day 7 Pre-Launch Competitor Discovery (Bidou28old)
**Task:** Pre-launch competitive scan — T-20min before Day 7 6 PM deployment  
**Deliverable:** Telegram alert (msg 2662) + daily notes entry  
**Self-Rating:** 4/5

**What I Did:**
- Scanned for POLY migration updates (none — story dormant since 14:40)
- Discovered Bidou28old story: $116K profit on Polymarket 5-min BTC/XRP bets (Feb 12-13)
- Verified via web_fetch: 52 trades, 83% win rate, only 3 losses
- Identified competitive angle: bot operated BEFORE 0% fee drop → validates "fees made it harder" narrative
- Confirmed regime-dependence (bot stopped after streak = validates Day 5 thesis)
- Sent Telegram alert with actionable reply strategy for Quill/Reuben

**What Worked:**
- ✅ 20-min buffer — delivered before Day 7 fired
- ✅ Finbold web_fetch confirmed all key stats (no rate limit)
- ✅ Actionable framing: specific tweet copy + engagement target (@ArunPanagar)
- ✅ Intel connects to Ruby's existing research (validates Days 5+7)

**What Didn't Work:**
- ⚠️ POLY migration story went cold (1 deleted post = weak signal, didn't develop)
- ⚠️ VectorPulser bot not fully analyzed (rate limit concern, also lower priority)

**Lesson Learned:**
- **Competitor discovery from news sites (Finbold, CoinDesk, etc.) is often more productive than Twitter/Reddit scans** — Twitter requires credentials, Reddit requires login. News aggregators return structured results fast.
- **Pre-launch intel windows are Fury's highest ROI time** — confirmed twice (14:40 + 17:40 both delivered actionable output before deployment). Pattern: scan 20-30 min before any major deployment.
- **Regime-dependent bots (start/stop) = natural regime detector validation**: Bidou28old operating Feb 12-13 (volatility spike) then stopping is real-world proof of Day 5 thesis. Always flag this cross-link.

### 2026-02-17 15:10 IST - Day 8 Kelly Criterion Intel + Reddit Gap Escalation
**Task:** Day 8 competitive intelligence + Reddit gap escalation  
**Deliverable:** Daily notes entry + Telegram alert to Reuben  
**Self-Rating:** 4/5

**What I Did:**
- Confirmed Reddit Post #1 still unsubmitted (gap from 14:25 persisted through all agents)
- Found Telegram chat ID (603633311) via sessions_list → deliveryContext
- Sent direct Telegram alert to Reuben with copy-paste ready Reddit body
- Found key Day 8 counter-argument: arxiv paper proving prices ≠ probabilities in prediction markets
- Validated Half-Kelly consensus across multiple practitioner sources (Jul 2025, Jan 2025, Dec 2024)
- Identified r/algotrading community sentiment aligns with Day 8 content

**What Worked:**
- ✅ Found Telegram chat ID via sessions_list (not config — that path was dead)
- ✅ Direct Telegram send worked (message #2651)
- ✅ Academic counter-argument (price≠probability) is high-value intel for Quill's Day 8 thread
- ✅ Half-Kelly validation: Day 8 approach is on solid practitioner ground

**What Didn't Work:**
- ⚠️ Multiple agents passed on Reddit gap (14:25 detection → 15:10 = 45 min drift)
- ⚠️ Early message tool calls failed: wrong target format — need to use sessions_list to find deliveryContext.to first

**Lessons Learned:**
1. **To send Telegram: use sessions_list first** — look for `channel: "telegram"` session → `deliveryContext.to` field contains the chat ID. Then `message(action=send, channel=telegram, target=<chatId>)`.
2. **When a gap persists through 3+ agent heartbeats: escalate to human immediately** — don't just update WORKING.md again. Direct Telegram message is the escalation path.
3. **For new content (Day 8): price≠probability gap is the standard academic critique of Kelly in prediction markets** — any social thread must address this or face blowback from quant audience.

